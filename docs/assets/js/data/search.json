[ { "title": "二十四分钟精通ClickHouse Materialized View", "url": "/posts/master-clickhouse-mv.html/", "categories": "技术", "tags": "ClickHouse, Materialized View", "date": "2023-02-12 00:00:00 +0800", "snippet": "ClickHouse是一个非常出色列数据库，对大数据量的实时分析有极佳的性能。本文用来介绍其MV（Materialized View，物化视图）的内部机制，帮助大家理解后更准确的使用。MV是一个trigger定义MV，实际上定义了一个insert trigger。数据数据写入source table时，会根据配置分成多个block，MV从block中读取数据，写入MV对应的storage t...", "content": "ClickHouse是一个非常出色列数据库，对大数据量的实时分析有极佳的性能。本文用来介绍其MV（Materialized View，物化视图）的内部机制，帮助大家理解后更准确的使用。MV是一个trigger定义MV，实际上定义了一个insert trigger。数据数据写入source table时，会根据配置分成多个block，MV从block中读取数据，写入MV对应的storage table中。 MV不会读取source table读取 调用一次insert时，MV select可能会被trigger多次如下图，展示了数据写入时的情况既然MV不从source table中读取，那极端情况如下图，当使用Null或者Kafka这样的Engine时，source table不会写入数据，但MV是可以存在的。MV使用普通table存储数据MV会将数据持久化存储，其存储的方式是采用一个普通的table，这种方式允许我们针对MV进行查询或者修改时，可以像普通表一样来进行操作，无需更多额外的知识。两种方式创建MV：直接创建使用如下的sql创建时，会隐式生成一个table，名称为 .innner.mv1CREATE MATERIALIZED VIEW mv1ENGINE = SummingMergeTreeORDER BY (id, d)ASSELECT id, d, count() AS cntFROM sourceGROUP BY id, d;使用TO创建使用如下的sql创建时，首先显示的创建名称为 dest的table，然后创建MV时通过 TO 指向该table。此时不会再创建隐式的inner table。CREATE TABLE dest(id String, d Date, cnt UInt64)ENGINE = SummingMergeTreeORDER BY (id, d);CREATE MATERIALIZED VIEW mv1TO destASSELECT id, d, count() AS cntFROM sourceGROUP BY id, d;区别Implicit table optimize_move_to_prewhere 在查询MV时不可用 可以使用populate在创建时插入数据 drop mv时，会自动drop inner tableExplicit table 不能使用populate创建，需要使用insert手动插入（见下文） drop mv时，dest table不会被删除如何使用使用 TO, ALWAYS 显示创建table方便运维，因为本身就是一张普通表，并且使其可见 polulate 实际不可用 他会针对所有的数据运行，数据越打，持续时间越长，甚至会超时或内存不足。这在7x24小时运行的系统中基本不会采用 在执行过程中插入到source table的数据不会被插入到MV中常见错误认为MV中的聚合计算是针对source table所有数据一个错误就是就是在插入数据时进行 max min avg 等由当前数据集决定的计算，例如CREATE MATERIALIZED VIEW mv1ENGINE = AggregatingMergeTreePARTITION BY toYYYYMM(hour)ORDER BY hourPOPULATEASSELECT toStartOfHour(time) hour,\tmaxState(cnt_by_minute) max_by_hour,\tsumState(cnt_by_minute) sum_by_hourFROM(\tSELECT minute, count() AS cnt_by_minute\tFROM source\tGROUP BY minute)GROUP BY hour上面的sql希望从source table中通过group 每分钟的计数创建每小时计数的MV，包括每小时内计数总和和以及最大的每分钟计数。如果使用 populate 那么初始化的max_by_hour是对的，但是后续的数据的计算会有问题，因为：MV的计算是针对插入的block，而不是source table所有数据当执行如下的两个sql，一次插入一条时，max_by_hour值为1，每次插入量条时，值为2-- sql1insert into source values (now()), (now());-- sql2insert into source values (now());insert into source values (now());认为source table的数据操作会影响MV中的数据MV对source table的修改是完全未知的，因为MV的数据读取不是从source table中，因此一下几种情况都是正确的： source table中数据删改，MV中数据不会变化 source table和MV可以存储不同时长的数据。例如source table中存储最近半年的数据，但是MV中存储10年以内的聚合数据MV with Replicated Engines正如前面所说MV的storage table就是普通的table，因此也可以像普通table一样使用Replicated Engine。创建方式 不使用 TO 创建时，要设置engine，这会创建在inner table 使用 TO 创建时，engine要设置在dest table中Replica机制其中要点包括： 数据写入发生在运行query的node中，写入其中的source table 插入的数据块会发送给其他node中对应的replicated table（例如从replica1发送到replica2）。 replica2不会从replica1直接读取 在node内，MV从写入source table的数据中获取数据 在创建时，此table使用了replicated engine，因此该table中的插入数据块，会被发送到其他node对应的replicated mv storage table中 每一个数据块是原子的、可去重的（通过checksum） 只有原始数据会进行发送，而不是merge之后的数据，以减少网络使用所以极端情况下，下图的情况是不可能发生的。写入一个node的source table，但是想replicate 到另一个node的replica source table所创建的MV中。Replication与数据的insert没有关系，它使用的数据插入part的 文件，而不是query的log。一般完整的使用replicated的MV如下图更新MVImplicit table (.inner.mv1) 停止数据写入 detach table mv1 alter table .inner.mv1 attach materialized view mv1DETACH TABLE mv1ALTER TABLE `.inner.mv1` ADD COLUMN b Int64 AFTER a, MODIFY ORDER BY (a, b)ATTACH MATERIALIZED VIEW mv1ENGINE = SummingMergeTreeORDER BY (a, b) ASSELECT a, b, sum(amount) AS sFROM sourceGROUP BY a, bExplicit table (TO dest) 停止数据写入 alter table dest drop table mv1 create materialized view mv1ALTER TABLE dest ADD COLUMN b Int64 AFTER a, MODIFY ORDER BY (a, b)DROP TABLE MV1CREATE MATERIALIZED VIEW mv1TO destSELECT a, b, sum(amount) AS s FROM sourceGROUP BY a, b说明 如果不停止写入，那么mv1 被detach或者删除后的数据将丢失 使用explicit table会直观很多，修改可见的dest table，drop mv1后重新创建即可不停机同步数据到MVMV通常不会在首次创建source table就创建，而是随着业务需求变化而创建。 这时创建MV既需要读取历史数据，也需要能处理线上正在不断写入的数据（针对7x24小时运行的系统）。 创建MV，在where条件中设置date列大于将来某个日期（一般mv都会包含一个date字段）。 上线并等到到该日期到达后，MV中将开始写入数据 插入该日期之前的数据 在第3步运行完成后， 此MV的数据将完整可用CREATE TABLE dest(a Int64, d Date, cnt UInt64)ENGINE = SummingMergeTreePARTITION BY toYYYYMM(d) ORDER BY (a, d);-- create MV с where date &gt;= in_the_futureCREATE MATERIALIZED VIEW mv1 TO dest ASSELECT a, d, count() AS cntFROM sourceWHERE d &gt;= '2023-02-14'GROUP BY a, d;-- arrives 2023-02-14INSERT INTO dest -- insert all for before in_the_futureSELECT a, d, count() AS cntFROM sourceWHERE d &lt; '2023-02-14' -- piece by piece by 1 month (or .. day) GROUP BY a, d;TAKEAWAY MV只是一个trigger，将数据存储到一个普通表 ALWAYS 使用 TO 创建MV MV不从source 读取数据，也不会因为source table的数据变更而受影响 MV的select中只处理当次传入的所有数据，而不是source table的所有数据参考： https://den-crane.github.io/Everything_you_should_know_about_materialized_views_commented.pdf https://clickhouse.com/docs/zh/sql-reference/statements/create/view/" }, { "title": "「二次创业」的窘境", "url": "/posts/second-startup.html/", "categories": "管理", "tags": "团队, 创业", "date": "2023-02-09 00:00:00 +0800", "snippet": "《创新者的窘境》一书提到一种现象：一个运营良好的企业，有充分的客户基础，他们倾听客户声音，不断增强产品，但却最终倒闭。听起来似乎不合理，但却真实的发生。过去一段时间，我们以「二次创业」的形式，上线了新产品 浩客。在已经有了金数据从零到千万用户的经验之上，整个过程应该要比较顺利才对，但还是经历了不少的的磨合与反复，还是值得思考。借用该书的名称，这也许就是「二次创业」的窘境。依赖的惯性 设计师...", "content": "《创新者的窘境》一书提到一种现象：一个运营良好的企业，有充分的客户基础，他们倾听客户声音，不断增强产品，但却最终倒闭。听起来似乎不合理，但却真实的发生。过去一段时间，我们以「二次创业」的形式，上线了新产品 浩客。在已经有了金数据从零到千万用户的经验之上，整个过程应该要比较顺利才对，但还是经历了不少的的磨合与反复，还是值得思考。借用该书的名称，这也许就是「二次创业」的窘境。依赖的惯性 设计师依赖产品经理给出Lo-Fi 研发依赖产品经理出详细的AC 研发依赖设计师给出Hi-Fi从角色上划分来看，上面的依赖十分正常，也是该角色该做的产出。但是在初创阶段，特别是整个产品的基础框架已经上线后，这种依赖不会带来更大的收益，反而可能会是前进的阻碍。产品经理要关注客户需求创业不是交付产品，而是帮助用户完成他的工作。此时产品经理的关注点更多应是客户的使用情况和需求反馈，他需要从宏观上保证产品方向的准确，是基于客户的，而不是闭门造车的。每一个合格的研发和QA有着足够的逻辑思考能力，来梳理不同功能的细节，产品经理澄清该功能的背景和价值，给出关键的场景，也许还有Lo-Fi就已足够。所以产品经理越是花费精力在功能的细枝末节，将自己这部分工作做到极致，反而越可能给整个产品带来方向性的风险。设计师要关注价值的呈现设计师在产品基础框架上线的过程中，与研发一起确定常用组件和UI规范，在这个规范之内，双方都进行有约束的设计和开发。在这之后，设计师需要更关注和思考产品的价值是否能准确的通过自身传达给用户。合格的研发有能力根据已有的页面进行组件的排布，设计师投入部分精力进行质量的验收即可，而无需每个功能都输出Hi-Fi。如果整个过程中，没有Hi-Fi就无法进行，那么或者前面的规范不足，或者基础框架没有扩展性。（BTW，Matine 是很推荐的React 框架，支持良好的自定义，对开发和设计都很友好）所以设计师越是专注在将产品的所有细节不断精深，在这个阶段产品整体可能越无法优化。研发要发散思考但深入浅出初创团队中的研发，绝不应是所谓的「工具人」或「螺丝钉」，作为团队中最理性的角色以及构建者，在开始着手编码前，需要： 协助产品经理明确其价值，其实简单的问几次为什么都很有作用 提出与直觉不相符、规范不匹配或者实现复杂的设计问题，避免做错误的事 仔细梳理逻辑，将缺失的不重要分支「自行补全」 思考当前功能是否可以拆分，而不是必须当做一个完整的功能一起上线 根据历史经验考虑扩展，但避免过度预先设计所以研发越是按部就班完成任务，那么就越会将产品经理和设计师拖入到内部视野之中，从而恶化上述两点。稳妥的惯性 任何需求，都需要产品经理拍板 任何样式，都需要设计师拍板 任何bug，都需要QA测试对于成熟产品，以上三点也许不仅重要，还会增加很多更多环节，来保证准确无误，因为在广泛的用户基础上，一点错误可能都会无限放大。对于初创产品，容错率会高很多，尽快的上线，解决某个需求到80%的程度，用户可能都非常开心。在细小的环节上，当成员有足够的信心时，这些稳妥的惯性不会带来更多好处。所以整个团队越是稳妥的前进，就越会失去创业最该需要的活力。想做正确的惯性工作中，谁都不愿意犯错，产品经理尤其如此，因为他是整个链条的入口，他的错误可能会带来整个团队无效的工作。但在初创阶段，唯一确定的就是不确定。通常情况下： 我们根据自身规划，来构建产品框架。但适用于最初阶段，或者某个大模块的开启之前 我们根据用户反馈，来优化产品功能。但用户量级不够，输入不足此时，试错是很好的突破。用小的成本进行线上验证和引导，启发用户来开拓更多方向和场景。这时，想做正确的惯性，会阻碍着尝试。所以越是想要做正确，就越会缺失了可能破局创新的机会。「二次创业」的窘境首次创业时，没有这些「良好」的惯性，可以在前进和探索中，轻装上阵，快马加鞭。二次创业时，这些「良好」的惯性，反而可能带来各种的束缚，这就是「二次创业」的窘境。「二次创业」的解答《创新者的解答》对如何避免陷入《创新者的窘境》做了解答，对于这里讨论的窘境问题，后续再来分享我们的解答。" }, { "title": "重视贡献，为成果而工作", "url": "/posts/focus-on-contribution.html/", "categories": "管理", "tags": "客户, 团队", "date": "2023-01-29 00:00:00 +0800", "snippet": " 有效的管理者重视对外界的贡献。他们并非为工作而工作，而是为成果而工作。 提出“我能做出什么贡献”的问题，是为了挖掘工作中尚未发挥的潜力。事实上许多工作看起来成绩辉煌，但是与潜在的贡献比起来，实在是微不足道。 重视贡献，才能使管理者的注意力不为其本身的专长所限，不为其本身的技术所限，不为其本身所属的部门所限，才能看到整体的绩效，同时也才能使他更加重视外部世界。只有外部世界才是产生成果的...", "content": " 有效的管理者重视对外界的贡献。他们并非为工作而工作，而是为成果而工作。 提出“我能做出什么贡献”的问题，是为了挖掘工作中尚未发挥的潜力。事实上许多工作看起来成绩辉煌，但是与潜在的贡献比起来，实在是微不足道。 重视贡献，才能使管理者的注意力不为其本身的专长所限，不为其本身的技术所限，不为其本身所属的部门所限，才能看到整体的绩效，同时也才能使他更加重视外部世界。只有外部世界才是产生成果的地方。 —— 彼得·德鲁克 《卓有成效的管理者》成果带来价值考虑如下场景：产品经理组织一个showcase，向市场、销售、客服等业务部门介绍准备上线的功能。大家都很兴奋，针对功能的细节展开激烈的讨论。接下来他综合大家的反馈，进行优化调整，并最终部署上线。这是日常迭代开发中一个非常普通的环节，通过内部演示，一方面周知不同团队新的功能，一方面收集更多的反馈以避免大面积的事故。产品经理完成了一个阶段性的工作目标，接下又很快投入到下一个目标的实现中。然而，所有这些只是工作的内容，产品经理的工作成果是什么呢？ 功能按时上线？ 其他部门同事知晓并理解了该功能？ 该功能在线上被客户使用？ 客户的工作因为该功能而更好地完成？显而易见，第4个答案更合适，因为它与组织的目标一致，而且它不是内部的结果，不由身边的同事来决定。由此为前提，产品经理的行动范围就自然扩大到更广的范畴： 分析客户的使用情况，完成同样目标所耗费的时间如何变化 访谈客户的使用体验，新功能带来的整体变化感知是否提升 跟进业务的使用反馈，对外部的宣传是否都正确合理的传达在这个范畴内完成的工作成果，才带来最终的价值。如何聚焦成果那么如何避免为了工作而工作，而是为成果而工作呢，在开始工作之前，可以追问自己如下的问题：客户、组织或者同事期望我的贡献是什么？采用这种方式思考，从成果出发来确定行动，能给予行动更具方向性的指导。以产研团队举例，从外部来需求来看，他们的贡献可以是：从客户角度他们希望使用产品过程顺畅、便捷，那么目标可以是： 通过仔细分析客户的使用情况，始终保持产品的易用，而不是随着功能的丰富，复杂度不断增加。例如通过费力度（CES）来衡量 保持对客户使用场景和需求的敏感度，真正协助客户完成其工作，避免闭门造车 提供良好的客户体验，不为了「炫耀」产品的能力而随意堆叠。例如通过NPS（推荐度）来衡量 构建良好的产品监控闭环，保持与用户的持续互动从市场/销售角度他们希望能向外界传达清晰的产品理念，那么目标可以是： 让每个人在完成自己的「As…, I want…, So that」时，都充分理解「So that」 梳理并使用一致的术语，确保我们与客户之间的沟通不存在歧义 通过业务人员，建立产研团队与客户之间的沟通渠道，从客户的角度来看待产研的产出从客服角度他们希望客户遇到问题时，可以更快得到解决，那么目标可以是： 产品自身提供良好的错误提示，客户可以根据提示，自主解决 提供高效的运营工具，帮助客服快速获得相关信息，定位问题 提供足够的系统监控，主动发现问题，先于更多客户发现而解决 不断优化CI/CD，保证客户7x24使用，保证出现问题时有及时修复的基础 针对产品问题问题，从根本上解决，避免重复出现，伤害客户体验和团队信心从组织角度他们希望成本可控，希望成员成长，那么目标可以是： 在产品型团队中，产研投入都是重中之重，既需要投入，又需要克制。因此要保持成本意识，持续优化人效 构建学习和成长的氛围，通过富有挑战的任务，获得各方面的提升，避免低效的重复为成果工作，重视贡献时，便不再强调自己的角色和能力，而是外部的需要，那么所谓的部门墙也就不会存在。如此，越是高阶管理者，直接成果就会趋向一致，那就是组织的使命。" }, { "title": "为什么Turbolinks发送了两次请求", "url": "/posts/turbolinks-request-twice.html/", "categories": "技术", "tags": "Turbolinks, Rails", "date": "2015-01-22 00:00:00 +0800", "snippet": "前面有一篇文章介绍过使用Turbolinks遇到的一个问题，最近又发现了另一个问题。开发时，tail后台的log会发现某些情况下，同一个请求会触发两次，不过因为都是get请求，而且同一个地址请求后的响应式相同的，所以前台不能完全察觉到。不够下面的场景跟预期就不一致了。假设需要一个功能可以在后台管理页面禁止用户账户，被禁止的账户在随后的所有访问当会重定向到禁止页面。从实现上来讲，当判断出用户的...", "content": "前面有一篇文章介绍过使用Turbolinks遇到的一个问题，最近又发现了另一个问题。开发时，tail后台的log会发现某些情况下，同一个请求会触发两次，不过因为都是get请求，而且同一个地址请求后的响应式相同的，所以前台不能完全察觉到。不够下面的场景跟预期就不一致了。假设需要一个功能可以在后台管理页面禁止用户账户，被禁止的账户在随后的所有访问当会重定向到禁止页面。从实现上来讲，当判断出用户的禁用状态后，就会清除他的登录session，然后重定向到禁止页面。但是现象是用户会直接跳转到登录页面，当重新登陆后，则看到禁止页。查看后台就发现同一个地址请求了两次，第一次清除了session，第二次再访问因为没有session就转向到登陆页面了。当然这种问题看看源码就清楚了，从Turbolinks的代码可以看出，在三种情况下，Turbolinks会尝试第二次请求同一个url。 response的状态吗在400到600之间 response header的content-type不匹配 /^(?:text\\/html application\\/xhtml+xml application\\/xml)(?:; $)/ 新页面的assets有变化,并且data-turbolinks-track为true时processResponse = -&gt; clientOrServerError = -&gt; 400 &lt;= xhr.status &lt; 600 validContent = -&gt; (contentType = xhr.getResponseHeader('Content-Type'))? and contentType.match /^(?:text\\/html|application\\/xhtml\\+xml|application\\/xml)(?:;|$)/ extractTrackAssets = (doc) -&gt; for node in doc.querySelector('head').childNodes when node.getAttribute?('data-turbolinks-track')? node.getAttribute('src') or node.getAttribute('href') assetsChanged = (doc) -&gt; loadedAssets ||= extractTrackAssets document fetchedAssets = extractTrackAssets doc fetchedAssets.length isnt loadedAssets.length or intersection(fetchedAssets, loadedAssets).length isnt loadedAssets.length intersection = (a, b) -&gt; [a, b] = [b, a] if a.length &gt; b.length value for value in a when value in b if not clientOrServerError() and validContent() doc = createDocument xhr.responseText if doc and !assetsChanged doc return docfetchReplacement = (url, onLoadFunction, showProgressBar = true) -&gt; triggerEvent EVENTS.FETCH, url: url.absolute xhr?.abort() xhr = new XMLHttpRequest xhr.open 'GET', url.withoutHashForIE10compatibility(), true xhr.setRequestHeader 'Accept', 'text/html, application/xhtml+xml, application/xml' xhr.setRequestHeader 'X-XHR-Referer', referer xhr.onload = -&gt; triggerEvent EVENTS.RECEIVE, url: url.absolute #在这里会判断response是否会返回doc body，如果为空，则直接在浏览器再请求一次该url if doc = processResponse() reflectNewUrl url reflectRedirectedUrl() changePage extractTitleAndBody(doc)... manuallyTriggerHashChangeForFirefox() onLoadFunction?() triggerEvent EVENTS.LOAD else document.location.href = crossOriginRedirect() or url.absolute" }, { "title": "Elasticsearch--更新策略", "url": "/posts/elasticsearch-update-strategy.html/", "categories": "技术", "tags": "Elasticsearch, Rails", "date": "2014-11-25 00:00:00 +0800", "snippet": "前一篇文章介绍了如何在Elasticsearch上做动态映射，这篇文章会介绍下如何更有效的做ES的数据更新。更新频率如果把ES看做另一个数据库，那么它总是会比系统原有的数据库滞后，因为数据会先存入原有数据库，再同步到ES。那么滞后的时间就是一个敏感的参数。根据业务的不同，差别很大。我了解到有的系统可以接受10分钟以上的延迟，不过我们作为一个数据平台，用户提交或修改数据后，是希望能立刻查询到修...", "content": "前一篇文章介绍了如何在Elasticsearch上做动态映射，这篇文章会介绍下如何更有效的做ES的数据更新。更新频率如果把ES看做另一个数据库，那么它总是会比系统原有的数据库滞后，因为数据会先存入原有数据库，再同步到ES。那么滞后的时间就是一个敏感的参数。根据业务的不同，差别很大。我了解到有的系统可以接受10分钟以上的延迟，不过我们作为一个数据平台，用户提交或修改数据后，是希望能立刻查询到修改的结果的，所以理论上是越短越好，但频繁的更新会给ES服务器带来很大的开销。异步更新更新可以采用同步和异步两种方式。 同步：使用elasticsearch-rails这个gem中的Automatic-Callback，在inlcudeElasticsearch::Model::Callbacks后，实际上就是在每一次数据增删改后使用callback来往ES发送请求。 异步：采用Asynchronous-Callback的方式，将每一次的更新放入队列。 同步的缺点是显而易见的，因为需要进行一次http请求与外部的服务器相连，影响原有的操作效率。特别是与ES的链接有问题时，会直接Timeout异常。因此在产品环境中一定要使用异步更新，它不仅规避了效率和稳定性问题，也让我们有了更大的灵活性在更新之前做更多的数据处理工作，例如后面要提到的数据聚合。聚合，使用Bulk API针对每一条数据的增删改就做一个更新，虽然是异步，但是在ES这边，是低效的，而且像我们这样每秒都有很多数据变化的系统是不现实的（实际上第一次上线时就采用这种方式，导致ES的CPU和内存急剧增加）。幸运的是，ES提供了Bulk API，并且也推荐使用它来进行批量的更新。一个简单的批量的请求体如下，它可以同时包含增删改操作，并且可以是多条。{ \"delete\": { \"_index\": \"website\", \"_type\": \"blog\", \"_id\": \"123\" }} { \"create\": { \"_index\": \"website\", \"_type\": \"blog\", \"_id\": \"123\" }}{ \"title\": \"My first blog post\" }{ \"index\": { \"_index\": \"website\", \"_type\": \"blog\" }}{ \"title\": \"My second blog post\" }{ \"update\": { \"_index\": \"website\", \"_type\": \"blog\", \"_id\": \"123\", \"_retry_on_conflict\" : 3} }{ \"doc\" : {\"title\" : \"My updated blog post\"} } 我们的更新策略是： 在一次更新时间内，将对数据的三种操作分别加入三个sidekiq队列，index, update和delete。 如果一次更新内，三个队列的优先级不同，例如如果一个数据同时在update队列和delete队列里，那么就从delete队列删除，这表示用户先更新了数据，然后又删除了，就只需要对ES做一个删除操作错误处理当sidekiq开始处理某些数据后，为了防止其它的sidekiq worker也去处理，需要将redis中对应数据暂时删除。但是如果因为某种原因出错，则还需要将这条数据重新加入队列中，以此来实现重试操作。需要注意的是，批量操作时，ES会将所有的数据更新状态都返回，系统需要根据是否出现error来从返回的结果中提取出错的数据，仅仅将这些数据重新加入队列，而不要简单的将所有数据都重新加回，增加负载。下面的文章介绍了更多信息https://www.found.no/foundation/keeping-elasticsearch-in-sync" }, { "title": "Elasticsearch--动态类型字段的mapping", "url": "/posts/elasticsearch-mapping.html/", "categories": "技术", "tags": "Elasticsearch", "date": "2014-11-24 00:00:00 +0800", "snippet": "ElasticSearch是一个基于Lucene构建的搜索引擎，通过RESTful的api可以进行数据的更新与搜索。目前github就是用的ES。通常来讲，如果是要进行精确的查询，可以直接针对数据库进行，合理的构建index，可以在数据库层面进行快速准确查询。然后在某些场景下，当数据集合的列无法确定时，很难加index，这会导致在数据量增大时性能严重下降。例如当前项目是一个在线表单，采用Mo...", "content": "ElasticSearch是一个基于Lucene构建的搜索引擎，通过RESTful的api可以进行数据的更新与搜索。目前github就是用的ES。通常来讲，如果是要进行精确的查询，可以直接针对数据库进行，合理的构建index，可以在数据库层面进行快速准确查询。然后在某些场景下，当数据集合的列无法确定时，很难加index，这会导致在数据量增大时性能严重下降。例如当前项目是一个在线表单，采用Mongodb作为数据库。当对表单和数据建模时就存在这样的问题，数据存储的每一列数据是不固定的，依赖于表单中该列字段类型的定义。这样就无法对数据中的列构建index。当对这一列进行排序，过滤时，不得不遍历当前表单下的所有数据。ES会对所有的字段构建自己的index和存储，这样不仅分散了数据库的访问压力，也避免了数据库缺失index的问题。这篇文章不是介绍如何从零开始使用ES，网上有很多的入门教程，从安装到运行hello world，此文以及后续的几篇文章将用来介绍我们如何更有效的在产品环境中使用ES。###如何对对动态类型字段如何做mapping动态类型的问题Mapping就是一个映射的定义，如何将系统中的数据类型映射到ES内。ES在内部对一个index下的type会根据mapping来进行存储，所以要求type中的每个字段类型必须一致。例如对一个User表，如果有个name字段，那么一条user数据中的name为string了类型的话，后续所有的user对象中的name都必须为string，否则做index时就会出错。但是在我们的系统中，Form对象存储了每个字段的定义，而数据对象Entry存储字段对应的值，这样不同的entry对象的同一个字段的类型基本上都不相同。例如Form1的第一个字段是文本类型的姓名，Form2的第一个字段可能是Hash类型的地址({province: ‘陕西省’, city: ‘西安’}),那么Form1下面的Entry的field_1值类型与Form2下地field_1值类型就完全不同，这样是无法直接index到ES的。dynamic templates一个简单的mapping定义如下，它将tweet的message属性映射为string{ \"tweet\" : { \"properties\" : { \"message\" : {\"type\" : \"string\" } } }}ES默认支持多种类型的定义，string, integer, array, object等等。因为我们系统中字段的类型不是无限多，所以我们采取了在字段后加入类型后缀来区分不同字段的方式来区分entry的不同字段。例如上面的Form1的entry第一个字段就是field_1_string，而Form2是field_2_hash,再加上ES的dynamic_templates就可以进行动态的定义了，例如下面的映射mappings: { entry: { date_detection: false, dynamic_templates: [ { strings: { match: '.*_string|_c_.*|.*_other', match_pattern: 'regex', match_mapping_type: 'string', mapping: { type: 'string', analyzer: 'ik' } }, { dates: { match: '.*_date|.*_datetime|created_at|update_at', match_pattern: 'regex', mapping: { type: 'date' } } }, { hashes: { match: '*_hash', mapping: { type: 'nested', } } }, { hash_propeties: { path_match: '*_hash.*', mapping: { type: 'string', index: 'not_analyzed' } } } ] }}这样定以后长生的mapping结果如下，可以看到有两个field_1的mapping，但是类型不同：{ \"field_1_string\" : { \"type\": \"string\", \"analyzer\": \"ik\" }, \"field_1_hash\" : { \"type\": \"nested\", \"properties\": { \"city\": { \"type\": \"string\", \"index\": \"not_analyzed\" }, \"district\": { \"type\": \"string\", \"index\": \"not_analyzed\" }, \"province\": { \"type\": \"string\", \"index\": \"not_analyzed\" }, \"street\": { \"type\": \"string\", \"index\": \"not_analyzed\" } }}}几点需要说明的地方 not_analyzed: 这个设置告诉ES不要分析这个值，在搜索的时候我会精确匹配这个字段的值，另外它也会加速index match_patten: 以指定使用’regex’，那么match条件就会去用正则表达式去匹配field名称，如果未指定，那么match中的*则为ES的通配符 path_match: mapping中第34行，这可以指定hash中的每个key的mapping类型 date_detection：JSON本身没有date类型的，ES会尝试将可能的date类型的字符串进行转换，这并不是我们需要的，因为虽然存储的是日期，但类型可能是字符串。因此需要显示的设置为false，然后提供一个template将系统中可能的date类型做mapping即可。mapping需要谨慎严格的定义，特别是像我们这样对象的数据类型是动态的，因为所有的数据都将根据它来同步，一般来说后续不太可能重新修改，常常需要重新index所有的数据，特别当产品环境的数据量到达千万甚至更多时，做一次完整的index，花费可以有数小时，甚至几天。下面这篇文章在开发的过程中给了不少思考：http://joelabrahamsson.com/dynamic-mappings-and-dates-in-elasticsearch/" }, { "title": "Rails CSRF token 探秘", "url": "/posts/secret-of-rails-csrf-token.html/", "categories": "技术", "tags": "Rails, CSRF, Ajax", "date": "2014-09-26 00:00:00 +0800", "snippet": "CSRF(Cross-Site Request Forgery)是一种常见的攻击手段，Rails中下面的代码帮助我们的应用来阻止CSRF攻击。class ApplicationController &lt; ActionController::Base # Prevent CSRF attacks by raising an exception. # For APIs, you may ...", "content": "CSRF(Cross-Site Request Forgery)是一种常见的攻击手段，Rails中下面的代码帮助我们的应用来阻止CSRF攻击。class ApplicationController &lt; ActionController::Base # Prevent CSRF attacks by raising an exception. # For APIs, you may want to use :null_session instead. protect_from_forgery with: :exceptionend这段代码是Rails4自动生成的，这里使用了with: :exception设置了对在handle_unverified_request使用的策略是抛出异常ActionController::InvalidAuthenticityToken。 Rails3中默认使用的reset_session。Rails防止CSRF的机制是在表单中随机生成一个authenticity_token，同时存储于表单的隐藏域以及当前的session中，当表单提交时，而server端就可以比较这两处的是否一致来做出判断，判断请求的来源是否可靠，因为第三方是无法知道session中的token的。# Sets the token value for the current session.def form_authenticity_token session[:_csrf_token] ||= SecureRandom.base64(32)end&lt;div style=\"margin:0;padding:0;display:inline\"&gt; &lt;input name=\"utf8\" type=\"hidden\" value=\"✓\"&gt; &lt;input name=\"authenticity_token\" type=\"hidden\" value=\"EZWDs44j5vzY+DCsgTHL0iPYiOUwaFnemwtGmo2AVRM=\"&gt;&lt;/div&gt;当然，这些都是正常情况，当表单要作为ajax提交，也就是data-remote=true时，情况就不同了，默认配置下，authenticityt_token不再自动生成。如果是Rails3就会发现session中的信息不见了，如果是把user_id存储在session中的，当然登录的状态就改变了。如果是Rails4，默认就会得到上面提到的InvalidAuthenticityToken异常。#form_tag_helper.rbdef html_options_for_form(url_for_options, options) options.stringify_keys.tap do |html_options| ... if html_options[\"data-remote\"] &amp;&amp; !embed_authenticity_token_in_remote_forms &amp;&amp; html_options[\"authenticity_token\"].blank? # The authenticity token is taken from the meta tag in this case html_options[\"authenticity_token\"] = false elsif html_options[\"authenticity_token\"] == true # Include the default authenticity_token, which is only generated when its set to nil, # but we needed the true value to override the default of no authenticity_token on data-remote. html_options[\"authenticity_token\"] = nil end end end上面代码的5-14行可以看到生成token时的配置判断，从中也可以得到解决的两种办法：1. 配置config.action_view.embed_authenticity_token_in_remote_forms = true2. 通过JS获取其实在默认的layout中，一般会有一行&lt;%= csrf_meta_tags %&gt;，它的定义是：def csrf_meta_tags if protect_against_forgery? [ tag('meta', :name =&gt; 'csrf-param', :content =&gt; request_forgery_protection_token), tag('meta', :name =&gt; 'csrf-token', :content =&gt; form_authenticity_token) ].join(\"\\n\").html_safe endend它在页面的head中增加一个csrf-token的属性meta content=\"authenticity_token\" name=\"csrf-param\" /&gt;meta content=\"VY13wlC2rgGccbkxyvm7Z1WX4LKH+71vzIj+8Um0QO8=\" name=\"csrf-token\" /&gt;这与表单渲染出的authenticity_token是完全一致的，所以这就给了我们通过js来给表单设置authenticity_token的办法，如下//application.js$('input[name=authenticity_token]').val($('meta[name=csrf-token]').attr('content'))" }, { "title": "Tricks On Upgrading Rails From 3.2 to 4.0", "url": "/posts/tricks-on-upgrading-rails-from-3-2-to-4-0.html/", "categories": "技术", "tags": "Rails,Mongoid,Capistrano,Upgrade", "date": "2014-08-26 00:00:00 +0800", "snippet": "很久一段时间以来，我们使用的都是Rails3.2 + Mongoid3，虽然Rails4发布已经快一年的时间了，但由于mongoid3不能支持Rails4，所以升级就一推再推，不过终于在近期Mongoid发布4.0以后完成了这次期盼已经的升级。心情是兴奋地，不过过程还是曲折的，不少细节，只看升级文档，或者google，不看源码还是真心不好解决。本文不是升级指导，因已经有很多文章，本文将对这次...", "content": "很久一段时间以来，我们使用的都是Rails3.2 + Mongoid3，虽然Rails4发布已经快一年的时间了，但由于mongoid3不能支持Rails4，所以升级就一推再推，不过终于在近期Mongoid发布4.0以后完成了这次期盼已经的升级。心情是兴奋地，不过过程还是曲折的，不少细节，只看升级文档，或者google，不看源码还是真心不好解决。本文不是升级指导，因已经有很多文章，本文将对这次升级遇到的问题做个简单的介绍，包括了Rails，Mongoid，Capistrano。READMORE每次升级有两个前提必须保证才可以稍微顺利一些： 完备的测试 通读官方升级文档。当然升级基本完成后才发现因为已经有Rails4已经有一年的时间，网上其实有不少可以参考的其他人的文章，中英文都可以，还有好心人翻译了国外的博文。###Strong Parameters它主要用来增强mass assignment的安全性，Rails3中通过使用attr_accessible在model层面进行控制，没有声明为attr_accessible的属性不能用mass assignment来赋值。但通常来说这个赋值的行为发生在controller级别，所以Strong Parameter将这样行为的限制上升在controller，并通过下面的格式来进行限制。params.permit(:name, {:emails =&gt; []}, :friends =&gt; [ :name, { :family =&gt; [ :name ], :hobbies =&gt; [] }])这其中定义了三种格式的参数类型，其中期望emails的值为Array的类型，而friends是一组Array的资源，有name属性，family的值为Array并含有name属性，hobbies的值则是Array类型。###controller测试异常缓慢我们使用的MiniTest，升级完成后运行controller测试时，非常非常的缓慢。后来发现当测试中request请求成功后，停在了在render layout那这一步，需要将近5分钟才可以完成。测试本身是成功的，而这5分钟也与asset precompile的时间类似。 Rails 4 no longer sets default config values for Sprockets in test.rb, so test.rb now requires Sprockets configuration. The old defaults in the test environment are: config.assets.compile = true, config.assets.compress = false, config.assets.debug = false and config.assets.digest = false.其中最主要的设置为# Don't fallback to assets pipeline if a precompiled asset is missedconfig.assets.compile = true此项设置的主要目的是当找不到precompiled的asset时是不是需要时时编译。当然，我们是不需要这样的设置的，所以当设置为false时就解决了这个问题。不过有个问题还是不明白，之前的默认值为true是如何正确工作的呢？###测试单独通过，rake test失败使用rake运行所有测试时，抛出TypeError: compared with non class/module无法定位是什么问题，好在有人遇到了一样的问题 https://github.com/freerange/mocha/issues/199,不要使用ruby2.0.0-p0，改为2.0.0-p353就好了。###Capistrano原先使用的是Capistrano2，由于Capistrano3做了很大的改动，所以为了平稳尽快完成Rails的升级，对Capistrano尽量做到最小的改动,这篇文章一定要看。其中两点最重要： 升级到2.15.4 将manifest.yml从shared/assets目录移到releases，并重命名为assets_manifest.yml，否则部署时会报错说有重复的manifest文件需要注意的是，升级之后在部署过中可能会看到一些err输出，实际上是Capistrano将info的输出信息作为err打印到console了。参见这里INFO messages while asset precompiling treated as errors###嵌入的支持Rails4会在response的header里增加一下的默认值，其中SAMEORIGIN限定了iframe在同一个domain中可以使用。如果取消这一限制有两种做法，一个是在下面的全局配置中将X-Frame-Options改为ALLOWALL。当然，如果只想针对单个请求，可以将这个设置在该请求的response中去除response.headers.except! 'X-Frame-Options'。config.action_dispatch.default_headers = {'X-Frame-Options' =&gt; 'SAMEORIGIN','X-XSS-Protection' =&gt; '1; mode=block','X-Content-Type-Options' =&gt; 'nosniff'}###Mongid中使用Only后的限制升级Mongoid4后，使用Only后的model对象将为只读，不可以再修改，否则会抛出下面的异常。检测document是否为只读可以直接在model上调用readonly?。在Mongoid3中没有这样的限制Mongoid::Errors::ReadonlyDocument:Problem: Attempted to persist the readonly document 'Entry'.Summary: Documents loaded from the database using #only cannot be persisted.Resolution: Donot attempt to persist documents that are flagged as readonly.另外使用only后，如果直接读取没有加载的属性，将抛出异常ActiveModel::MissingAttributeError: Missing attribute: 'not_load_attr’。在Mongoid3中返回nil。下面是一些升级指导的链接 http://edgeguides.rubyonrails.org/upgrading_ruby_on_rails.html#upgrading-from-rails-3.2-to-rails-4.0 http://www.oschina.net/translate/get-your-app-ready-for-rails-4 https://ruby-china.org/topics/15579 http://www.sitepoint.com/get-your-app-ready-for-rails-4/" }, { "title": "Nginx 与 Unicorn", "url": "/posts/nginx-unicorn.html/", "categories": "技术", "tags": "Capistrano, Nginx, Rails, 部署", "date": "2014-03-10 00:00:00 +0800", "snippet": "Capistrano, Nginx 与 Unicorn的搭配作为Rails应用的部署方式是现在成熟与流行的模式，Deploying Rails app using Nginx, Unicorn, Postgres and Capistrano to Digital Ocean这篇文章详细介绍了如何来使用，本文希望稍微深入一些来看看Nginx与Unicorn之间是如何通信的，以及Unicorn...", "content": "Capistrano, Nginx 与 Unicorn的搭配作为Rails应用的部署方式是现在成熟与流行的模式，Deploying Rails app using Nginx, Unicorn, Postgres and Capistrano to Digital Ocean这篇文章详细介绍了如何来使用，本文希望稍微深入一些来看看Nginx与Unicorn之间是如何通信的，以及Unicorn如何实现部署时做到了零宕机。READMORE####UnicornUnicorn是应用服务器，以master/workers的模式工作。当master进程启动时，会将整个应用加载到内存中，之后会fork出若干个worker，master不处理任何请求，这时worker的工作。master进程管理所有的worker，它清楚每个worker处理请求的时间，当超过某个阈值时，会kill掉这个worker，并立刻fork出一个新的，以防止大量耗时的请求将worker耗尽。fork一个worker是瞬间完成的。####负载均衡传统的负载均衡是会基于某种算法（例如根据worker上次一个处理的时间）将下一个request加入到worker的队里中，但是如果很不幸这个worker正在处理的是一个耗时的操作，那么队列中的后续请求就block了。而unicorn的负载均衡是Unix系统内核完成的，所有的worker在就绪时通过unix的select(2)来从队列中（这里的队列其实是shared listen socket）抓取请求。通过这种方式，请求队列在master进程上，而一旦有可用的worker，就可以立即进行处理，而不会出现前面的问题，除非所有的worker都在处理慢请求，那只能等到超时后被master kill掉，然后重新fork出worker。当然，如果出现这种情况，就是系统本身有问题或者遭到了攻击。零宕机部署Capistrano是一个简单易用的自动化部署工具，可通过脚本配置，将应用部署到多个服务器中，支持在不同的部署阶段执行相应的任务。不过零宕机部署的主要功劳在unicorn。在部署时，我们会向当前的unicorn master进程发送USER2信号，它会开始创建一个新的master进程，重新加载应用。之后fork它自己需要的worker。第一个fork出的子进程会发现还有另一个旧的master进程，那么就会向它发送QUIT信号，旧master会等待自己所有的worker完成当前的请求后终止。由于旧的worker会继续处理完当时的请求，所以用户不会察觉到程序的修改，而同时，新的master和worker已经开始工作，所有新来的请求会由新的worker处理，这样就实现了零宕机。 QUIT - graceful shutdown, waits for workers to finish their current request before finishing. USR2 - reexecute the running binary. A separate QUIT should be sent to the original process once the child is verified to be up and running. unicorn_pid = \"#{shared_path}/pids/unicorn.pid\"test -s unicorn_pid &amp;&amp; kill -USR2 `cat #{unicorn_pid}`当然，这只是针对的仅有代码修改的部署。如果牵扯到数据库迁移，就不能简单的这样处理，因为数据库是在新旧worker之间共享的。不过也可以通过迁移脚本来尽可以达到这个目的，这就是另一个话题了。###NginxNginx是一个http服务器和反向代理服务器，功能强大，而且配置起来并不复杂。下面简单介绍一下其中的几个主要概念。####upstream它定义了一组server，可以通过unix的socket，也可以是domain name或者IP地址。这里使用那种方式需要根据与unicorn设置的配合来确定，如果在unicorn中设置了listen某个端口，则nginx也要使用端口，如果unicorn中设置了listen某个socket，则unicorn中就要指定socket的位置，这个就是ngxin与unicorn通信的地方。upstream除了可以定义server的地址以外，还可以作为进行负载均衡的设定。通过设置weight来改变默认的权重，也可以使用默认的方法，例如least_conn来设定使用连接最少的server，ip_hash来设定将同一个ip的request发送给同一个server。upstream example { server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/var/apps/example/tmp/sockets/unicorn.sock;}#unicorn.rblisten 8090listen APP_ROOT + \"/tmp/sockets/unicorn.sock\"###server它定义了一个虚拟的server，下面的配置定义都非常表意，需要注意的时proxy_pass，这里使用了上面定义的upstream，也就是将所有的请求都转向到example这一组server上。nginx在处理request时是有一定顺序的，例如下面的定义中，nginx会检测request header中的HOST是example.com还是example.net来匹配不同的server。而在匹配的server中，还会根据location的设置来匹配不同的设置，例如请求的是example.com/test.gif，则会匹配第二个location，从而在增加一个30天的过期时间。server { listen 80; server_name example.com; root /var/apps/example/current/public; index index.html index.htm; access_log /var/log/nginx/example_access.log info; error_log /var/log/nginx/example_error.log; location / { proxy_pass http://example; } location ~* \\.(gif|jpg|png)$ { root /var/apps/example/current/public; expires 30d; }}server { listen 80; server_name example.net;}上面只是简单介绍了一下unicorn和ngxin如何工作以及如何配置，下面的一些文章有更详细的介绍： http://sirupsen.com/setting-up-unicorn-with-nginx https://blog.engineyard.com/2010/everything-you-need-to-know-about-unicorn https://github.com/blog/517-unicorn http://tomayko.com/writings/unicorn-is-unix http://nginx.org/en/docs/http/ngx_http_upstream_module.html http://nginx.org/en/docs/http/request_processing.html" }, { "title": "支付宝集成——校验与应答", "url": "/posts/alipay-verify-request.html/", "categories": "技术", "tags": "支付宝", "date": "2014-01-04 00:00:00 +0800", "snippet": "前一篇文章介绍了如何生成支付宝的请求URL，当顺利打开支付宝的登录页面后，这里的操作就与应用本身无关了，完全在支付宝内部完成。当用户的交易状态改变，比如付款成功时，支付宝会通过POST发送请求URL中设定的notify_url。由于通常都需要在回调中进行业务逻辑处理，因为，为了防止恶意或伪造请求，需要对该请求进行严格的校验。MD5校验按照请求URL中的规则，对参数再进行一次MD5运算，与传递...", "content": "前一篇文章介绍了如何生成支付宝的请求URL，当顺利打开支付宝的登录页面后，这里的操作就与应用本身无关了，完全在支付宝内部完成。当用户的交易状态改变，比如付款成功时，支付宝会通过POST发送请求URL中设定的notify_url。由于通常都需要在回调中进行业务逻辑处理，因为，为了防止恶意或伪造请求，需要对该请求进行严格的校验。MD5校验按照请求URL中的规则，对参数再进行一次MD5运算，与传递过来的sign值进行比较，这是为了保证URL的完整性，参数的值没有在传递过程中被篡改，因为需要的KEY值只有支付宝和系统内部可知。READMORE支付宝校验对网页版的支付异步回调，支付宝提供了专门的service来校验合法性。在收到POST请求的一分钟内，可以请求下面的地址，如果返回的body是个字符串true，则这是个有效的通知。手机版是没有这个校验service的。https://mapi.alipay.com/gateway.do?service=notify_verify?partner=xxxxx&amp;notify_id=xxxxx支付宝的异步通知规则为,所以当异步回调成功处理之后，一定要返回success文字，并且要在业务逻辑上注意检测是否已经处理过该请求，防止重复处理。 程序执行完后必须打印输出“success”(不包含引号、前后无空格和其他多 余字符)。如果商户反馈给支付宝的字符不是 success 这 7 个字符,支付宝 服务器会不断重发通知,直到超过 24 小时 22 分钟。一般情况下,25 小时以内完成 8 次通知(通知的间隔频率一般是: 2m,10m,10m,1h,2h,6h,15h)此篇与上篇文章介绍了与支付宝交互的内部流程，实际在开发中有很多库可用，它们主要提供了生成URL，校验，以及通知内容的封装等。基于Ruby On Rails的技术栈，我们采用了下面两个gem： activemerchant：这个集成了全球流行的支付网关 activemerchant_patch_for_china：这个gem集成了 alipay (支付宝), 99bill (快钱), tenpay (财付通), 19pay(捷迅支付) and yeepay(易宝)在支付宝手机网页支付方面，由于当时没有找到现成的gem，所以就是自己实现了。前两天在上看到Ruby China上的这篇文章介绍了一个gem，专门用于支付宝，可以通过查看它的源代码来了解实现细节。不够这个gem似乎也还不包括手机移动支付的部分。" }, { "title": "支付宝集成——生成请求URL", "url": "/posts/alipay-generate-request-url.html/", "categories": "技术", "tags": "alipay", "date": "2014-01-03 00:00:00 +0800", "snippet": "去年的这个时候，开始开发基于支付宝的收费模块，现在已经运行了快到一年。这期间从担保交易到即时到帐，再到支持手机支付，经历了用户真正的验证后，今天来总结一下支付宝集成中得注意事项。当然要先申请支付宝的商家服务，拿到PID和Key，并至少签约成即时到帐、双工或者担保交易的一种。以开发的角度，从发起到结束可以分为以下两个主要步骤：生成请求URL（网页版和手机版的生成方式是不同的），支付宝回调校验和...", "content": "去年的这个时候，开始开发基于支付宝的收费模块，现在已经运行了快到一年。这期间从担保交易到即时到帐，再到支持手机支付，经历了用户真正的验证后，今天来总结一下支付宝集成中得注意事项。当然要先申请支付宝的商家服务，拿到PID和Key，并至少签约成即时到帐、双工或者担保交易的一种。以开发的角度，从发起到结束可以分为以下两个主要步骤：生成请求URL（网页版和手机版的生成方式是不同的），支付宝回调校验和应答。这里先来说一下生成请求URL的注意事项。READMORE电脑网页版生成请求URL这会是一个普通的GET请求，支付宝的网关是，https://mapi.alipay.com/gateway.do，需要在网关后增添上需要的参数。如果请求成功，可以看到支付宝的登录页面。其中有几个需要注意的参数： 同步转向地址return_url：用户支付成功以后的同步转向页面 异步通知地址notify_url：当用户的交易状态发生任何变化（比如买家已付款，卖家已发货等）的时候，支付宝都会以POST方式来请求这个地址，并传递相应的参数。 sign和sign_type：支付宝要求对请求的参数需要做MD5加密，除了这两个参数以外，其它的参数都需要跟据字母顺序排序后加密。 商户订单号out_trade_no：这里可以定义为系统中的某个唯一的值，它与支付宝的订单号一一对应。 logistics_fee, logistics_type, logistics_payment：如果是担保交易，则必须指定这三个关于快递的参数。手机网页支付生成请求URL手机网页支付与电脑网页支付有很大的不同： 手机端只支持即时到帐交易 手机端数据交互格式不是普通的URL的参数，而是xml格式，在请求中的req_data参数需要传入的格式应该如下： &lt;direct_trade_create_req&gt; &lt;subject&gt;#{options[:subject]}&lt;/subject&gt; &lt;out_trade_no&gt;#{options[:out_trade_no]}&lt;/out_trade_no&gt; &lt;total_fee&gt;#{options[:price]}&lt;/total_fee&gt; &lt;seller_account_name&gt;#{options[:seller_email]}&lt;/seller_account_name&gt; &lt;call_back_url&gt;#{options[:call_back_url]}&lt;/call_back_url&gt; &lt;notify_url&gt;#{options[:notify_url]}&lt;/notify_url&gt; &lt;/direct_trade_create_req&gt; 手机端请求URL时分两步，首先获取token，再以token请求支付页面 第一步，请求移动网关http://wappaygw.alipay.com/service/rest.htm，参数包含一些基本参数和上面的req_data外，要指定service为alipay.wap.trade.create.direct。当然也是需要MD5加密的（支付宝也支持RSA加密，不过由于我们的系统允许用户输入自己的PID和KEY来使用，所以我们选择了简单的MD5加密）。 第二步，解析返回的参数，取出token，然后构造执行的请求req_data为 &lt;auth_and_execute_req&gt;&lt;request_token&gt;#{token}&lt;/request_token&gt;&lt;/auth_and_execute_req&gt; 再一次请求移动网关，并将service设为alipay.wap.auth.authAndExecute。幸运的话，应该就能在手机上看到手机的支付宝登陆页面了。 生成URL中最长出现的错误可能就是MD5加密的错误，这时通常需要检查加密参数的顺序是否正确，或者参数是否完备或有多余了。" }, { "title": "常用易混的四个Rails View Helper方法", "url": "/posts/some-rails-helper-methods-those-are-confusing.html/", "categories": "技术", "tags": "Rails", "date": "2013-12-01 00:00:00 +0800", "snippet": "Rails中有非常多强大的View Helper，今天其实想在这里简单总结其中4个与安全相关但又容易混淆的。它们分别是: h, html_safe, simple_format, sanitize。READMOREh我们经常需要在页面上动态展示文字，这些完全可能来自用户的输入。所以为了防止XSS，在页面渲染时，需要对文字进行转义。在Rails2时，经常见到如下的代码&lt;%= h some...", "content": "Rails中有非常多强大的View Helper，今天其实想在这里简单总结其中4个与安全相关但又容易混淆的。它们分别是: h, html_safe, simple_format, sanitize。READMOREh我们经常需要在页面上动态展示文字，这些完全可能来自用户的输入。所以为了防止XSS，在页面渲染时，需要对文字进行转义。在Rails2时，经常见到如下的代码&lt;%= h some_text %&gt;其中h方法就是进行转义操作，它的同义方法为html_escape。当然在Rails3之后，h方法已经是默认调用，所以不要再显示出现了。从源代码可以看出，这里会对四种符号进行转义（&amp;”’&gt;&lt;），也就是在Rails的console中可以尝试如下代码include ERB::Util =&gt; Object&gt; puts html_escape(\"is a &gt; 0 &amp; a &lt; 10?\")is a &amp;gt; 0 &amp;amp; a &amp;lt; 10?html_safe其实h方法的实现依赖此方法，其实现中首先判断是否是html_safe，如果是就直接返回，否则做转义替换。def html_escape(s) s = s.to_s if s.html_safe? s else s.gsub(/[&amp;\"'&gt;&lt;]/, HTML_ESCAPE).html_safe endendhtml_safe是个很容易理解错误的方法。它不是像方法名那样将调用的对象转换为安全的，而是变成了另一个类型。它是打开String后添加的一个方法，因此可以在任何String上调用，返回一个SafeBuffer对象。class String def html_safe ActiveSupport::SafeBuffer.new(self) endendSafeBuffer是个特别的类，它覆写了String的+, « 和 []，当在erb中输出时，它不进行转义，而当给它concat一个普通的String时，它会对连接的这个字符转义。可以这样理解这个对象，它认为自己是“Safe”的缓冲池，当你给它连接字符时，则需要将其转义来保证“Safe”，而如果连接的同样是个“Safe”的对象，就不要转义了。并不是在页面上输出所有的字符时我们都需要转义，一个典型的应用场景如下（引用自http://makandracards.com/makandra/2579-everything-you-know-about-html_safe-is-wrong）：def group(content) html = \"\".html_safe html &lt;&lt; \"&lt;div class='group'&gt;\".html_safe html &lt;&lt; content html &lt;&lt; \"&lt;/div&gt;\".html_safe htmlendsimple_format这个方法比较好理解，顾名思义，用来格式化字符串的，主要的目的是将两个或多个换行符(\\n)替换成(p)， 一个换行符替换成(&lt;br /&gt;)sanitize它提供了比h方法更加灵活转义策略，可以自定义不需要转义的tag。例如需要在页面显示让用自定义某些style时，就可以可以允许&lt;style&gt;标签，而不将其转义。" }, { "title": "Build Phonegap Application using CoffeeScipt Scss and Haml", "url": "/posts/build-phonegap-using-coffee-scss-haml.html/", "categories": "技术", "tags": "PhoneGap, CoffeeScript", "date": "2013-06-04 00:00:00 +0800", "snippet": "Refer to phonegap-scaffoldPhoneGap is a tool that allows developer to build cross platform mobile native application using javascript, html and css.This is great, however, the raw js, html and css ...", "content": "Refer to phonegap-scaffoldPhoneGap is a tool that allows developer to build cross platform mobile native application using javascript, html and css.This is great, however, the raw js, html and css is outdate. There are plenty of techniques that can be used to improve the efficiency. For example, CoffeeScript for javascript Haml for html Scss for cssREADMOREAll of these “new” tech have clear syntax and can be easiliy compiled to raw files.For development purpose, we also need: Autocompile to raw files Rake tasks to run test. Jasmine for JavaScript Different urls for different environment. (developement, uat, production, etc) Rake tasks to deploy app to simulators for quick look Ajust styles in browser, no need to deploy each timeSo I create a repo in github called phonegap-scaffold." }, { "title": "Rails中隐藏的check_box", "url": "/posts/hidden-checkbox-in-rails.html/", "categories": "技术", "tags": "Rails", "date": "2013-06-02 00:00:00 +0800", "snippet": "Rails中，我们经常会在form中使用check_box这个helpler方法，在controller中，可以通过params[:category]来获取category的值。然而，如果检查一下check_box这个helper方法生成的html代码，会有点不如想象那样直接可懂。例如下面一个简单的form中&lt;%= form_for(@post) do |f| %&gt; &lt;d...", "content": "Rails中，我们经常会在form中使用check_box这个helpler方法，在controller中，可以通过params[:category]来获取category的值。然而，如果检查一下check_box这个helper方法生成的html代码，会有点不如想象那样直接可懂。例如下面一个简单的form中&lt;%= form_for(@post) do |f| %&gt; &lt;div class=\"field\"&gt; &lt;%= f.label :category %&gt; &lt;%= f.check_box :category %&gt;是否设置类型 &lt;/div&gt; &lt;div class=\"actions\"&gt; &lt;%= f.submit %&gt; &lt;/div&gt;&lt;% end %&gt;READMORE&lt;input name=\"post[category]\" type=\"hidden\" value=\"0\" /&gt;&lt;input id=\"post_category\" name=\"post[category]\" type=\"checkbox\" value=\"1\" /&gt;是否设置类型上面就是那个check_box生成的html代码，问题是为什么会有一个与期望的input同名的隐藏域呢？而且它已经被设定为value是0，那么它将伴随着表单提交而提交上去，这样的话，在controller里面是如何拿到正确的值的呢？其原因是这样的： 浏览器不会提交没有选中的checkbox，所以，如果没有那个隐藏域，当checkbox没有选中时，这个字段将不会有值post后台。结果会是，当这个字段有check的值存储以后，将无法再更改为uncheck的值。 上面的html或者只提交隐藏域，或者提交同名的两个字段。HTML规范中规定表单字段提交的顺序与在表单中出现的顺序是相同的，最后一次出现的值代表了该字段的值。因此无论该checkbox是否选中，后台都可以得到对应的值。BTW，如果是要使用checkbox group，则需要指定{:multiple =&gt; true}，并且避免将uncheck的默认值设为nil。" }, { "title": "不要心存侥幸", "url": "/posts/be-vigilant-all-the-time.html/", "categories": "技术", "tags": "部署", "date": "2013-05-30 00:00:00 +0800", "snippet": "已经过去了整整12个小时，不过依然清晰的记得早上宕机的那漫长的十分钟，如此煎熬。第一次经历产品宕机，突然之间，QQ，反馈表单，NewRelic，到处都是500的报告，产品经理也无法忍受突如其来的打击而情绪激动。而这一切都只是因为我一点点的大意。这是临时发现的一个IE7的样式问题，解决方案就是在layout中加入对IE7 fix的css文件。考虑到这会影响到部分用户的正常使用，我决定立刻修复它...", "content": "已经过去了整整12个小时，不过依然清晰的记得早上宕机的那漫长的十分钟，如此煎熬。第一次经历产品宕机，突然之间，QQ，反馈表单，NewRelic，到处都是500的报告，产品经理也无法忍受突如其来的打击而情绪激动。而这一切都只是因为我一点点的大意。这是临时发现的一个IE7的样式问题，解决方案就是在layout中加入对IE7 fix的css文件。考虑到这会影响到部分用户的正常使用，我决定立刻修复它。于是，本地修改，运行自动化测试，手动测试，提交。我们有一个UAT环境，通常来说，会先部署到这个环境，测试无误后再部署到产品环境。”不过这次需要么？就像前面已经有过好几次一样，很小的修改，快速的fix 应该没问题的。而且为了确保安全，还专门运行了所有测试“，这就是当时我脑中的想法。于是一个命令开始了自动化的部署产品环境，紧接着就是痛苦的开始。READMORE修复问题，再次部署，盯着屏幕，漫长的等待，很长很长时间。。。也许以后这可以看作宝贵的经验，不再造成更大的损失，不过现在，它确实让人失望和沮丧。不要心存侥幸，前面的成功不是下一次成功的借口。绝大部分的时候，多用几分钟，稳扎稳打才是最节省时间和最正确的。" }, { "title": "Turbolinks导致的表单重复提交警告问题", "url": "/posts/turbolinks-make-form-resubmissioin.html/", "categories": "技术", "tags": "PRG, Rails, Turbolinks", "date": "2013-02-28 00:00:00 +0800", "snippet": "Turbolinks将在Rails4中会被默认引入，它类似于PJAX，但是会托管整个页面的body部分，在页面跳转时，不会重新加载整个页面，而是使用JavaScript重写页面并且更新浏览器中的地址，从而使页面访问的速度大大加快。尽管Rails4还没有正式发布，但现在的项目已经在使用Turbolinks了，它不需要任何额外的配置，添加到Gemfile后即可。最近遇到了一个问题如下：几乎所有的...", "content": "Turbolinks将在Rails4中会被默认引入，它类似于PJAX，但是会托管整个页面的body部分，在页面跳转时，不会重新加载整个页面，而是使用JavaScript重写页面并且更新浏览器中的地址，从而使页面访问的速度大大加快。尽管Rails4还没有正式发布，但现在的项目已经在使用Turbolinks了，它不需要任何额外的配置，添加到Gemfile后即可。最近遇到了一个问题如下：几乎所有的应用都会有表单的验证、错误显示、提交并重定向等，比如下面的rails controller中的create action，当post成功存储以后，重定向到post列表页面，如果存储失败，render当前新建页面，由于post实例变量的存在，new页面被render时会自动填入用户已经输入的信息以及validation的错误信息。READMOREdef create @post = Post.new(params[:post]) if @post.save redirect_to @post else render action: \"new\" endend这里的重定向遵循了PRG模式(post-redirect-get)，这样当用户点击后退或者刷新页面都不会出现表单重复提交的警告。但是加入Turbolinks之后，当表单提交成功，然后刷新页面，仍然会出现表单重复提交的警告。Turbolinks的文档中提到的如果想禁止它，可以在container的标签上加入data-no-turbolink。不过这样尝试仍然不工作。从表现来看，浏览器页面在表单提交后整个刷新，是一个302redirect，但是似乎post请求的状态始终还在。找不到根本的原因，所以有了下面的解决方案：def create @post = Post.new(params[:post]) if @post.save render :json =&gt;; {:redirect_url =&gt; posts_path} else render :partial =&gt; \"form\", :status =&gt; 400 end end$(document).on \"ajax:complete\", \".post form\", (event, xhr, status) -&gt; if status == \"success\" res = $.parseJSON xhr.responseText Turbolinks.visit res.redirect_url else $('.entry-show.entry').html xhr.responseText如上面的代码， 使用Ajax提交表单，在rails中也就是将原有的表单增加一个:method=&gt;true的属性。 在controller中对象保存成功之后返回Json或者text，里面包含需要转向的url。 在Ajax的success回调中使用Turbolinks.visit path方法“转向”到成功的地址。实际上是JavaScript重新页面，速度很快如果保存失败，比如校验不通过等，需要重新render界面，并回显相关信息。这时不能直接像成功后的回调那样使用visit方法，这将丢失原来的信息。如果将所有的参数手动传入呢，当然也不可取。我这里采取的方法，是原有的表单提取为partial，并在controller中保存失败后render。而在Ajax的回调中失败时，将返回的partial写入页面，替换原来的表单。因为这个partial是在controller中渲染好的，所以保存了所有的输入和验证信息。通过使用Ajax提交表单，成功解决了Turbolinks引入的表单重复提交警告的问题，而且加速了页面的显示。" }, { "title": "Backbone中的Model", "url": "/posts/model-of-backbone.html/", "categories": "技术", "tags": "Backbone, Javascript", "date": "2013-02-15 00:00:00 +0800", "snippet": "Backobone是一个JavaScript的前端框架，使具有复杂交互的页面实现能更加清晰。其中Model是核心的部分，它主要主要有下面几个方面： 控制着Backbone中View呈现的内容 与Backbone中Collection的交互 承载着校验，数据运算等功能 与服务端交互的桥梁Backbone代码一个很显著的特点就是看到满篇的this.model，对新手来说理解这里的mode...", "content": "Backobone是一个JavaScript的前端框架，使具有复杂交互的页面实现能更加清晰。其中Model是核心的部分，它主要主要有下面几个方面： 控制着Backbone中View呈现的内容 与Backbone中Collection的交互 承载着校验，数据运算等功能 与服务端交互的桥梁Backbone代码一个很显著的特点就是看到满篇的this.model，对新手来说理解这里的model到底是什么以及怎么样传递，什么时候要toJSON，什么时候直接传递，有一点不够直接。这里主要来介绍一下在Model与Collection和View通信中容易混淆的一些场景，希望有所帮助。READMOREModel与ViewBackbone中的View主要用来展示Model以及绑定各种事件回掉。View需要与Model绑定可以有两种方式。 通过构造函数初始化 var PostView = Backbone.View.extend(); var Post = Backbone.Model.extend(); var post = new Post({title: \"post title\"}); var postView = new PostView(post); var anotherPostView = new PostView({model: post}); var anotherPostView2 = new PostView({model: post.toJSON()});上面的代码都是通过构造函数将model传如一个View中，唯一的不同是postView是直接传入model对象，anotherPostView是传入了一个hash对象，key值为model，而anotherPostView2则是将post转换为JSON后传入。这三种有什么不同呢？Backbone的View构造函数可以接受参数，默认传入的参数可通过this.options来访问，postView就是这种情况。但是一些特别的参数例如model（其他的参数还有collection, el, id, className,tagName和attributes），如果anotherPostView，model会直接添加到View对象中，可以通过this.model调用，这时的结果是整个post对象，拥有Backbone Model的所有方法。获取title的方式是this.model.get(‘title’)anotherPostView2与anotherPostView不同在于model被转化为了JSON对象，所以获取title的方式为this.model.title。那么应当选取哪一种呢？三种方式都可以满足基本的数据展示需求，只是调用方式的不同，不过推荐使用第二种，因为完整的model对象拥有更完整的事件机制。比如，希望在model改变的时候重新渲染view，那么就可以通过下面的方式 this.model.on('change', this.render, this);这样的基础是，当通过set改变model的属性时，会自动出发change事件。 通过render方法传入modelView最重要的方法就是render，它决定如何展现数据。稍微复杂一些的View通常会通过underscore的template方法生成DOM模板，然后传入Model替换其中的Pleaceholder。例如Backbone的网站上给出的例子。 var Bookmark = Backbone.View.extend({ template: _.template(…), render: function() { this.$el.html(this.template(this.model.attributes)); return this; } });这里的model可以在render方法中传入，然后进一步传入模板中。注意，传入模班的model调用了attributes方法，也就是toJSON，因为在模板中通常直接调用JSON中的key。那么这两种model与view的关联方式如何取舍呢？我的经验是，如果View只服务于特定的model，那么就在构造函数传入。如果随着model的不同，我们希望这个View可以渲染不同的模板，而View是同一个对象，那么就在render时调用，需要的话在render方法中使用 this.model = model将传入的model应用于当前View的model。Model与CollectionCollection是Backbone中一组有序的Model集合，当页面需要管理多个同种类型的Model时，Collection提了很多的便利，例如很多的集合操作，基于集合的事件。Collection可以指定包含的model对象类型，例如var Posts = Backbone.Collection.extend({ model: Post});var posts = new Posts();posts.add(post);posts.add({title: \"a new post\"});前三行定义了一个Post的Collection，后面向其中添加了两个post，一个是Model对象，一个是hash对象。虽然添加的方式不同，但是当被添加到集合之后，它们的存储都是一样的，因为hash对象会被转换为对应的model对象，如果model定义了initialize方法，还会去调用它。相对于View与Model，Collection与Model的关联方式要简单许多。这里简单的分析了view与collection中的model用法，相信即使对backbone不是了解，现在看到满篇的this.model应该不会头疼了。" }, { "title": "从交付到产品", "url": "/posts/from-delivery-to-product.html/", "categories": "工作", "tags": "压力, Delivery, 产品, 客户, Rails", "date": "2013-02-13 00:00:00 +0800", "snippet": "这是一个七人的小团队产品组，正式加入刚好有一个月了。说长不长，不过可总结的倒是有一些。之所以会有些感慨，因为相对于前面所有的项目，这是比较特别的一个。在公司将近三年的时间里，前前后后经历了四个项目,.Net, Java, Rails, Android，完全不同的技术栈。第一个.Net项目，跟着胡凯学习如何写程序，学习什么是敏捷工作。第二个Java项目，在米高的指导下学习如何代表一个团队与国外...", "content": "这是一个七人的小团队产品组，正式加入刚好有一个月了。说长不长，不过可总结的倒是有一些。之所以会有些感慨，因为相对于前面所有的项目，这是比较特别的一个。在公司将近三年的时间里，前前后后经历了四个项目,.Net, Java, Rails, Android，完全不同的技术栈。第一个.Net项目，跟着胡凯学习如何写程序，学习什么是敏捷工作。第二个Java项目，在米高的指导下学习如何代表一个团队与国外的客户沟通。第三个Rails项目，作为Tech Lead与澳洲的团队一起工作，与国内团队共享知识。最后一个短期的Android项目，以IM(Iteration Manager)的身份参与两个多月，与客户沟通需求，在短期内从零开始建立起Jira管理所有的需求。所有的这些我能看到自己一点一点的改变。而不变的是实实在在的客户，他们有需求，有计划，有鼓励，有疑问。而这些，在产品组则有很大不同。READMORE用户和客户在交付团队，虽然没有接触过用户，不过客户时刻都在。从需求，设计，到最后BAT，这样一个循环的周期都是来自于客户而终于客户。在产品团队，客户与用户的角色是合二为一的，他们到无处不在是却又无法具体。这是个有意思的转变，首先是没有客户来帮你计划什么功能多久发布，并且间接的告诉你用户有了什么新的需求和为什么会改变。这里只能通过分析，以及用户试用的反馈，来推论需求。有趣的一件事是有位同事说，我们的单选和多选应该增加其他选项，而我告诉他这就是那天要上线的功能。在交付团队，或者因为远离真正的用户，或者因为欠缺领域知识，很多时候只是从技术方面给予客户更多。而当用户可能就是身边的任何一个人时，关注反馈，了解市场成了工作中重要的环节。因为这是需求的来源，这决定着优先级的高低。Story同样以Story来进行功能的切分和管理。交付团队中，我们会习惯每个story都有详细的AC，因为这是团队之间沟通的契约，BA，DEV，QA，Producer，每个角色都会详细的分析每个AC，确保INVEST原则。而在产品团队，即便复杂的story可能描述也只是简明扼要的说明主要功能，配上不同页面的设计图片。详细的AC固然好，但是一方面这样的小型团队没有足够的精力，另一方面，开发人员有很大的主动性，他们了解这个功能的价值，就可能对详细的设计有足够的challenge，或许从实现的技术方案方面，或许从感觉用户的实际使用方面。可以称作灵活，因为可以BAT的人就在身边，任何可行的改动可以简单到只要一句话通知即可完成。进度与压力刚刚经历过的那个项目有一个IM和一个Producer，都是客户的人员，IM负责交付，Producer负责功能。这是一个天然的矛盾体，在固定的时间内，IM希望上线承诺的功能，而Producer希望更多功能上线。如果功能太少，那是Producer的责任，如果承诺多了而无法保证，那是IM的责任。于是，很多次看到这两个角色为了是否做某个功能挣得不可开交。 对交付团队来说，我们只能是给出我们的估计，并且所有人将这样的矛盾转化为大家无形的交付压力，希望同时满足他们两个人。而在进度方面，影响的因素会有很多，比如突然发现某个需求不很清晰，这样一来二去的讨论而耽误。又或者依赖的某个外部环境不工作了，必须要等待其他团队修复。在产品团队，因为没有具体的服务对象，无论团队的成员是否有意无意的给予，压力都是来自于自己心里。记得我刚刚加入后仅仅和团队中唯一一个比较有经验的成员pair了两天，便开始需要独立工作。依稀记得那个story基本上属于一边看着已有代码，一边理解和猜测它的逻辑，一边尝试修改，一边还要讲给另一个刚毕业半年的应届生讲。我能感觉到压力，那种想要尽快贡献力量的迫切心态，与对代码逻辑陌生而缓步前进的矛盾带来的压力。《黑客与画家》中提到 在越大的团队中，每个人的贡献就越接近平均水平相反，在越小的团队中，每个人的价值和能力就越容易凸显。这种轻易可视化也是带来压力的重要方面，特别是当你想要表现的更好时。开发-上线-探索交付团队中，更多的工作是功能的开发，上线之后，便进入下一个开发的循环之中。产品组则不同，更像是开发-上线-探索。每次IPM一个必要的环节是分析线上系统的运行统计情况，包括，客户端浏览器和设备，应用的入口点，访问的页面，停留时间等等，通过这样的监控，了解用户的使用情况，还有用户直接通过系统提供的反馈，往往是bug或者一些使用上的增强，进而探索更适合用户的功能。持续部署当所有一切都在可控的范围内时，事情会变得很有意思，或者说足够灵活。比如在部署和发布方面，如果上午验收测试完毕，下午就可以发布到产品环境。如果发现产品上出现什么比较严重的bug，会立刻将手中的工作切换到主干分支上，修复，提交，发布。当然这种灵活建立在对产品足够的信心之上，对质量提出了更高的要求。参与过的交付项目中，测试是保证质量的重要方式，TDD，质量检查工具，这些都是必须的，而这里，没有硬性的覆盖率要求。但不意味着为了进度而没有测试，更何况没有测试只会让刚开始看起来快一些。TDD带来的好处已经无需论证，这里只是在测试的策略上更加灵活一些。这方面不知有没有规则可循，不过现在更多的是经验，或者建立在教训上的经验。这些是一些零散的感受，总结为几个词的话，灵活，可控，但要自律。新年的愿望，希望产品能顺利发展。金数据 https://jinshuju.net" }, { "title": "MapReduce: 一个i和1导致的悲剧", "url": "/posts/mapreduce-loop-problem.html/", "categories": "技术", "tags": "MapReduce, MongoDB", "date": "2012-11-26 00:00:00 +0800", "snippet": "听说MapReduce已经很久了，这两天才第一次真正的尝试一下。要说的是因为一个很简单的错误，折腾了好一会儿，刚好让我有了更多的理解。因祸得福吧。要实现的是一个很简单的功能，统计每一天新增的数据的数量，以天为单位，数据库中的created_at字段存储是以秒为单位的。考虑到将来这样的数据可能会非常大，所以使用MapReduce就成了自然的选择。READMORE我使用的是mongodb,最开始...", "content": "听说MapReduce已经很久了，这两天才第一次真正的尝试一下。要说的是因为一个很简单的错误，折腾了好一会儿，刚好让我有了更多的理解。因祸得福吧。要实现的是一个很简单的功能，统计每一天新增的数据的数量，以天为单位，数据库中的created_at字段存储是以秒为单位的。考虑到将来这样的数据可能会非常大，所以使用MapReduce就成了自然的选择。READMORE我使用的是mongodb,最开始的代码如下：def map &lt;&lt;-MAPfunction() { d = new Date(this.created_at.getFullYear(), this.created_at.getMonth(), this.created_at.getDate()); d.setSeconds(#{Time.zone.utc_offset}); emit(d, 1);} MAPenddef reduce &lt;&lt;-REDUCEfunction(key, values) { var result = 0; for (i in values) { result += i; } return result;} REDUCEend这是从网上一个地方找的例子。MapReduce的原理就是首先根据给定的条件做group操作，然后根据聚合后的每个小单元进一步操作。最后会得到一个hash的数组，{“_id” =&gt; key, “value” =&gt; value},其中的key就是map操作时emit操作的第一个参数， value是从reduce操作中的返回值。这段代码看似正确，先在map中将数据库中的时间戳字段映射到每一天，在reduce中取出已经被map过的值，循环加一即可，因为这里只是关心数量，而没有其他的运算，甚至可以将那个for循环替换为 return values.length都可以。事实证明，在小数据量时，这个结果是正确的，所以我的测试通过了，但是当运行大规模数据时，结果差了很多，几千条数据就有一个数量级的差距，而且毫无规律。为什么呢？答案其实就在MongoDB MapReduce的文档中！简单的拷贝过来而不深入思考，这个问题很严重！ When you run a map/reduce, the reduce function will receive an array of emitted values and reduce them to a single value. Because the reduce function might be invoked more than once for the same key, the structure of the object returned by the reduce function must be identical to the structure of the map function’s emitted value.也就是说reduce方法是会被多次调用的，所以Map中emit的object需要和Reduce中的返回值结构一致，这样当被多次调用的时候，结果才会被merge在一起。在加入一些调试信息可以发现，map和reduce都是会被多次调用的，而且并不是map完毕之后才调用reduce，两者是交互进行的。回头再看前面那段代码，如果将1换成i其实就是正确的，可能误操作将i改成了1，并且自己想当然的给了一个解释才导致了这个小悲剧的发生。思考，理解，不能想当然！http://www.mongodb.org/display/DOCS/MapReduce" }, { "title": "Inside CoffeeScript：语法强壮", "url": "/posts/inside-coffeescript-2.html/", "categories": "技术", "tags": "CoffeeScript, Javascript", "date": "2012-05-26 00:00:00 +0800", "snippet": "前一篇文章主要说了CoffeeScript的语法强大的几点，它极大的简化了JS的语法，更清晰简洁，另外很重要的一点是它从语法本身的角度避免了JS的若干陷阱。1. ==JS中，使用双等号比较时，它会尝试进行类型转换再比较，这就导致了下面的几个问题console.log('' == '0'); //falseconsole.log(0 ==''); //trueconsole.log(0 ...", "content": "前一篇文章主要说了CoffeeScript的语法强大的几点，它极大的简化了JS的语法，更清晰简洁，另外很重要的一点是它从语法本身的角度避免了JS的若干陷阱。1. ==JS中，使用双等号比较时，它会尝试进行类型转换再比较，这就导致了下面的几个问题console.log('' == '0'); //falseconsole.log(0 ==''); //trueconsole.log(0 == '0'); //true而在CoffeeScript中，如果使用==，将会自动编译为===，这从根本上解决了这个问题，另外还提供了一些更具语义的方法名，如 is, isnt等。READMORE2. LoopCoffeeScript有两种循环，针对数组的for … in和针对对象的for … of。其中针对对象的循环在JS本身是具有陷阱的。JS中对对象的循环会将对象整个原型链中的属性全部都包括进来，所以通常需要使用hasOwnProperty方法来判断属于当前对象自身的属性而排除原型链的属性。CoffeeScript并没有根本解决这个问题，但提供了own 关键字简化了解决方案myRect = x: 100 y: 200Object.prototype.z = 300#x,y,zfor key, value of myRect console.log key #x,yfor own key, value of myRect console.log key3. Binding先看下面的例子class Foo constructor: (@value) -&gt; display: -&gt; console.log @value robustDisplay: =&amp;gt; console.log @valuefoo = new Foo(20)foo.display(); #20foo.robustDisplay(); #20anotherDisplay = foo.displayanotherRobustDisplay = foo.robustDisplayanotherDisplay() #undefinedanotherRobustDisplay() #20前面的两次调用都返回20，这是我们期望的值，但是当调用another*方法时，第一个返回了undefined，而第二个正确。这是怎么回事呢，不过是给了另一个别名，就导致了错误。仔细观察会发现错误的方法使用的是“-&gt;”，而正确的方法使用了“=&gt;”(Fat Arrow)。要找到根本的原因，得要提一下JS的Scope和Context的概念&lt;&lt;CoffeeScript: Accelerated JavaScript Development&gt;&gt;一书中给出了这样的描述 Scope: A variable’s scope is its home, as defined by three rules: Every function creates a scope, and the only way to create a scope is to define a function. A variable lives in the outermost scope in which an assignment has been made to that variable. Outside of its scope, a variable is invisible. Context(==This): When the new keyword is put in front of a function call, its context is the new object. When a function is called with call or apply, the context is the first argument given. Otherwise, if a function is called as an object property (obj.func) or obj[‘func’]), it runs in that object’s context. If none of the above apply, then the function runs in the global context. 简单说scope就是定义时变量的可见性，context是运行时this所指的对象环境。例子中的两个方法的实现中都输出this.value。那么当使用foo对象去o调用时，this指的就是foo对象，从而第一个执行都正确返回。当使用another*时，this对象已经发生了变化，而不再指向foo，所以anotherDisplay()返回了undefined,因为global对象并没有value值。那么anotherRobustDisplay()为什么正确呢，看看它编译的JS就清楚了this.robustDisplay = __bind(this.robustDisplay, this);在编译出的代码中有上面一个调用，它的作用就是将对robustDisplay绑定在当前对象中，而不随着调用者的变化而变化，这样它将可以知道value值。上面只是列举了几个小例子，用以展现CoffeeScript的语法强壮之处。当然，使用的时候还是要特别注意： 与python一样，它使用缩进表示层次关系，所以编辑器的空格与tab键一定要统一 像ruby一样，方法调用传递参数可以省略括号，所以方法链调用特别要注意，推荐除非特别简单，否则都使用括号 参数之间的空格也要特别注意，省略括号时，是否有空格会对表意产生巨大影响" }, { "title": "Inside CoffeeScript：语法强大", "url": "/posts/inside-coffeescript-1.html/", "categories": "技术", "tags": "CoffeeScript, Javascript", "date": "2012-05-26 00:00:00 +0800", "snippet": "第一次听说CoffeeScript是Rails 3.1将它作为默认的支持，第二次深入的理解是Nodejs的兴起，CoffeeScript用它独特的语法样式，使我这个面向对象出身的程序员在写JavaScript时找到了似曾相识的感觉。当然如果对它的理解仅仅停留在语法的简化，那么只能说对JS(The World’s Most Misunderstood Programming Language)...", "content": "第一次听说CoffeeScript是Rails 3.1将它作为默认的支持，第二次深入的理解是Nodejs的兴起，CoffeeScript用它独特的语法样式，使我这个面向对象出身的程序员在写JavaScript时找到了似曾相识的感觉。当然如果对它的理解仅仅停留在语法的简化，那么只能说对JS(The World’s Most Misunderstood Programming Language)本身并不熟悉。« JavaScript语言精粹 »一书中提交了很多JS本身语法存在的缺陷，例如全局变量，分号自动补全，==等。CoffeeScript的golden rule是“It’s just JavaScript”, 但是它如何避免这些陷阱，则从另一方面体现了它的强大。本文将从语法强大方面来举例分析。READMORE1）函数默认参数 + 字符串连接favorite = function(language){ if(language == null){ language = 'CoffeeScript'; } console.log(\"I love \" + language + \" best\");}favorite()favorite = (language = 'CoffeeScript') -&gt; console.log \"I love #{language} best\"2）可变参数Splats这样一个例子：足球赛事中，一般的排名是，冠军，亚军，和其他球队，这里再复杂一点，加上最后一名。也就是：GivenallTeams = ['Chelsea', 'Bayern', 'Barcelona', 'Real Madrid', 'Milan', 'Inter', 'HengDa']Output:champaion: Chelsearunner-up: Bayernothers:Barcelona, Real Madrid, Milan, Interlast:HengDa用JS和CoffeeScript分别实现var allTeams = ['Chelsea', 'Bayern', 'Barcelona', 'Real Madrid', 'Milan', 'Inter', 'HengDa'];order = function(teams) { var champion = teams[0]; var runnerup = teams[1]; var others = teams.length &gt;= 3 ? teams.slice(2, teams.length - 1) : []; var last = teams[teams.length - 1]; console.log(\"Champion is \" + champion); console.log(\"Runnerup is \" + runnerup); console.log(\"others are \" + others); console.log(\"last is \" + last);};order(allTeams);allTeams = [ 'Chelsea' 'Bayern' 'Barcelona' 'Real Madrid' 'Milan' 'Inter' 'HengDa']order = (champion, runnerup, others..., last) -&gt; console.log \"Champion is #{champion}\" console.log \"Runnerup is #{runnerup}\" console.log \"others are #{others}\" console.log \"last is #{last}\"order allTeams...3）Destructing Assignment在Ruby中有同样的语法，下面的例子实现了Fibonacci数列#Fibonacci[last, current] = [0,1]for i in [0..10] console.log last [last, current] = [current, current + last] console.log last更加强大的是当右侧是一个对象时，会根据该对象的属性进行赋值：class Shape constructor: (@width) -&gt; computeArea: -&gt; throw new Error('I am an abstract class!')class Square extends Shape computeArea: -&gt; Math.pow @width, 2class Circle extends Shape radius: -&gt; @width / 2 computeArea: -&gt; Math.PI * Math.pow @radius(), 2#The instanceof operator tests presence of constructor.prototype in object prototype chain.showArea = (shape) -&gt; unless shape instanceof Shape throw new Error('showArea requires a Shape instance!') console.log shape.computeArea()showArea new Square(2) # 4 showArea new Circle(2) # pimyRect = x: 100 y: 200{x: myX, y: myY} = myRect#定义了myX和myY两个变量，并调用myRect.x和myRect.y分别赋值console.log myXconsole.log myY#当定义的变量名称与右侧对象的key值相同时，可以更精简为{x, y} = myRectconsole.log xconsole.log y4）class与inheritance定义了class与extends来是语法来包装JS使其更加类似面向对象的语言。给个简单例子class Shape constructor: (@width) -&gt; computeArea: -&gt; throw new Error('I am an abstract class!')class Square extends Shape computeArea: -&gt; Math.pow @width, 2class Circle extends Shape radius: -&gt; @width / 2 computeArea: -&gt; Math.PI * Math.pow @radius(), 2 #The instanceof operator tests presence of constructor.prototype in object prototype chain.showArea = (shape) -&gt; unless shape instanceof Shape throw new Error('showArea requires a Shape instance!') console.log shape.computeArea()showArea new Square(2) # 4 showArea new Circle(2) # pi" }, { "title": "Inside Ruby: Eigenclass", "url": "/posts/inside-ruby-eigenclass.html/", "categories": "技术", "tags": "Metaprogramming, Ruby", "date": "2012-02-03 00:00:00 +0800", "snippet": "在Inside Ruby: Object Model中提到，object拥有method，但是method并不存在于object中，而是在class中，这样同一个class的不同实例可以共享method。我们知道在Ruby中，可以定义singleton method，这种method只针对某个特定的object定位，而其它的object则没有该方法。如下面的片段：obj = Object.n...", "content": "在Inside Ruby: Object Model中提到，object拥有method，但是method并不存在于object中，而是在class中，这样同一个class的不同实例可以共享method。我们知道在Ruby中，可以定义singleton method，这种method只针对某个特定的object定位，而其它的object则没有该方法。如下面的片段：obj = Object.newdef obj.my_singleton_method puts 'one singleton method'endobj.my_singleton_method # =&gt; \"one singleton method\"Object.new.my_singleton_method # =&gt; NoMethodErrorREADMORE那么对于singleton method如何用上述理论来解释呢？my_singleton_method不能存在于obj中，因为obj不是class，它也不能存在于Object这个class中，因为如果那样的话，所有的Object实例都会有这个方法，不会抛出异常。对class method也可以做同样的分析，因为不同的类实际是Class的不同对象，从属于某个类的class method，其它类是不会有该方法的。实际上，对每个object(class也是一种对象)，它还可以有一个特殊的隐藏的class，这就是Eigenclass(也叫Singleton class，Meta class)。class Object def eigenclass class &lt;&lt; self self end endendclass A class &lt;&lt; self def a_class_method; end endendobj = A.newclass &lt;&lt; obj def a_singleton_method; endendobj.eigenclass # =&gt; Classobj.class # =&gt; Aobj.eigenclass.superclass # =&gt; Aobj.eigenclass.instance_methods().grep(/a_sin/) # =&gt; [:a_singleton_method]上面的代码片段中，首先在class Object上加入一个eigenclass方法，用于返回被隐藏的eigenclass，然后给class A定义一个class method，给class A的实例obj定义一个singleton method。从运行的结果可以看出： ruby的class并没有告诉我们“真相”，obj的class方法返回结果实际上应该是eigenclass而不是A。&lt;/li&gt; obj的method存在于它的eigenclass的instance method中，这就回答了最开始提出的那个singleton method到底存在何处的问题&lt;/li&gt;再看下面的片段class B &lt; A ; endB.methods.grep(/a_/) # =&gt; [:a_class_method]B.superclass.eigenclass.instance_methods.grep(/a_/) # =&gt; [:a_class_method]这里想要说的是当向上寻找一个class method的时候，实际上是沿着eigenclass的super class来寻找的，也就是说一个类的eigenclass的superclass是它的superclass的eigenclass。《Metaprogramming Ruby》一书对这些有非常详细的解释，推荐参考。" }, { "title": "Inside Ruby: Object Model", "url": "/posts/inside-ruby-object-model.html/", "categories": "技术", "tags": "Metaprogramming, Ruby", "date": "2012-02-02 00:00:00 +0800", "snippet": "今天来重新了解一下ruby的Object Model，之所以是重新，因为是从内部来看，而不是从外部的使用上。1. objectobject = instance variables + methods(包括一个指向所属class的方法)。使用object.instance_variables 和object.methods可以查看对应的信息, 区别在于前者存在于object本身，而metho...", "content": "今天来重新了解一下ruby的Object Model，之所以是重新，因为是从内部来看，而不是从外部的使用上。1. objectobject = instance variables + methods(包括一个指向所属class的方法)。使用object.instance_variables 和object.methods可以查看对应的信息, 区别在于前者存在于object本身，而method存在于object的class中，这些method在class中被称作instance method，这也是为什么同一个class不同object可以共享方法，但是不能共享instance variable。2. classclass也是一个object，是Class的实例，拥有instance methods和指向父类的方法superclass。Class是Module的子类，所以一个class也是一个module。3. modulemodule与class没有根本差别，因为class本身就是module的子类，但是引入module与class的目的是不同的。通常来说，class用来实例化和继承，而module用来mix in或者作为namespace。READMORE下面的代码片段展示了部分上述内容class MyClass def my_method @v = 'instance variable' endendobj = MyClass.newobj.instance_variables # =&gt; []obj.my_methodobj.instance_variables # =&gt; [:@v]obj.methods == MyClass.instance_methods # =&gt; trueMyClass.class # =&gt; ClassClass.superclass # =&gt; ModuleModule.superclass # =&gt; ObjectMyClass.superclass # =&gt; Object4. include先看下面的代码module A; endmodule B; endclass BaseClass; endclass MyClass &lt; BaseClass include A include BendMyClass.ancestors # =&gt; [MyClass, B, A, BaseClass, Object, Kernel, BasicObject]MyClass.superclass # =&gt; BaseClass在面向对象的语言中，当我们调用方法的时候，首先会在当前类中寻找，如果找不到，则会去父类中，然后是父类的父类。Ruby中提供了一个superclass方法，顾名思义是返回父类，但是Ruby并不是按照superclass的返回结果层层向上寻找方法。与Java和C#一样，Ruby不允许多继承，但是Module的引入使得它有所不同，不同在于，Ruby是按照ancestors的返回结果来寻找，这个ancestor tree中包含了class和module。所以，Ruby查找方法的顺序为：当前类 -&gt; include的module的逆序，-&gt; 继承的父类。原因在于 ，Ruby中，当在一个class中include一个module时，它会创建一个匿名类，包装那个module，并且将这个匿名类插入祖先树中，仅仅在当前类之上。而superclass对此一无所知。《Metaprogramming Ruby》一书对这些有非常详细的解释，推荐参考。" }, { "title": "Feature Toggle", "url": "/posts/feature-toggle.html/", "categories": "技术", "tags": "Feature Toggle", "date": "2012-01-29 00:00:00 +0800", "snippet": "每个迭代(两周)发布一次，所有功能必须完整可用。这对项目的计划，story的划分都提出了很高的要求。然而有的功能很难在一个迭代内完成，例如某个story在临近迭代结束的时候开始，或者某个系统的某个特性需要持续若干迭代的开发， 在整体完成之前不能出现在产品中。那么如何控制未完成的功能不出现在产品中而又不影响新的代码开发呢？这时就需要引入Feature Toggle。在Rails中Feature...", "content": "每个迭代(两周)发布一次，所有功能必须完整可用。这对项目的计划，story的划分都提出了很高的要求。然而有的功能很难在一个迭代内完成，例如某个story在临近迭代结束的时候开始，或者某个系统的某个特性需要持续若干迭代的开发， 在整体完成之前不能出现在产品中。那么如何控制未完成的功能不出现在产品中而又不影响新的代码开发呢？这时就需要引入Feature Toggle。在Rails中Feature Toggle可以分为三个部分： 定位配置文件：比如toggle的名称，开关属性，使用环境等，下面的文件中表示有个show_user_name的feature，只在qa和staging环境中打开 show_user_name: switch: on when: [qa,staging]&lt;/pre&gt; 实现解析配置文件的Ruby文件：这个文件最主要是在Object对象上实现一个方法，用于判断配置文件中定义的标志位的状态。 class Object def show_feature? feature_name feature_toggle.active? feature_name end ... end 使用：调用show_feature?方法，并传入toggle的名称，以此来控制是否执行相关代码。 从使用角度来说，并没有多大的难度，但下面两点必须要注意，否则会有很大的可能产生问题： Feature Toggle的应只针对尚未完成的功能，而不是作为选择功能的控制器。功能完成之后，就立刻删除与该feature相关的所有控制代码。特别要摒弃的思想是保留已经完成的功能，但是把该功能关掉，以备将来使用。这完全可以从源码控制工具中轻松得到，而一旦保留在代码中，就需要增加额外的维护成本。 测试。对使用Feature Toggle的每个功能都需要测试打开与关闭两种场景，因为两种条件下可能都会对其他功能产生影响。我们的项目中曾出现过一个功能完成之后，就一直关闭，很长时间以后在产品环境中打开，因为觉得那个功能对其他都没有影响，但是却导致了系统异常。Feature Toggle是实现持续发布的重要手段，但当控制的条件较多时，就一定是什么地方出了问题，好用但不能滥用。下面的文章有有更加深入的解释：http://martinfowler.com/bliki/FeatureToggle.html" }, { "title": "软件发布实战 -- 沟通", "url": "/posts/releae-in-action-communication.html/", "categories": "工作", "tags": "Release, Migration", "date": "2011-11-04 00:00:00 +0800", "snippet": "沟通在任何一项团队活动中都非常重要, 下面的一个例子发生在我们的一次发布中.这次我们对数据库进行了重构, 将原来的一个大表拆分成若干小表, 那么除了做表结构的迁移,还需要做数据迁移, 因为在产品环境中已经存在了一些数据.产品环境的数据还算比较干净, 针对这种理想状态数据的\b迁移, 我们使用存储过程很快实现. 但是在QA环境和Staging环境中, 由于有各种测试, 而且这些数据从几个月前很早...", "content": "沟通在任何一项团队活动中都非常重要, 下面的一个例子发生在我们的一次发布中.这次我们对数据库进行了重构, 将原来的一个大表拆分成若干小表, 那么除了做表结构的迁移,还需要做数据迁移, 因为在产品环境中已经存在了一些数据.产品环境的数据还算比较干净, 针对这种理想状态数据的\b迁移, 我们使用存储过程很快实现. 但是在QA环境和Staging环境中, 由于有各种测试, 而且这些数据从几个月前很早的版本中就写入了数据库. 为了让迁移脚本更加强壮,保证产品环境万无一失, 又经过反复的修改, 终于可以随意的迁移,回滚,再迁移.但是事情没有想象的那么顺利. 在上线的时候发现 产品的数据库不支持\b新建和执行存储过程. 这是我们从来没有考虑过的.一切的基础设施能力都是我们自己的感觉. 现在只有两种方案: 修复产品数据库存储过程的问题. 这不是我们可控的, 而且对ops团队来说, 这件事优先级可能会非常低, 需要极大的推动. 而且这次肯定无法上线 丢弃我们的产品数据. 听起来很荒谬, 但是去问了producer, 却得到了非常轻松的答案, 我们产品两个月后上线真正开始销售时会把整个遗留数据都清除一边. 所以现在可以不用保留. 这样的答案听起来轻松的一点是解决了所有的问题, 但汗颜的是我们花了几天的时间做了一个完全无用的工作, 如果在做之前询问一下是否需要保留这些数据, 那么前面的工作就会轻松许多. 所以软件发布中也需要足够的沟通, 除了BA, Dev, OPs, 还有producer." }, { "title": "软件发布实战 -- 集成", "url": "/posts/releae-in-action-integration.html/", "categories": "工作", "tags": "Release, Integration, Heroku, Test", "date": "2011-10-16 00:00:00 +0800", "snippet": "作为一个程序员， 每天开心的新程序，让所有的测试通，最后打浏览器，输入“localhost/newapp”， 看到开发的功能展现在眼前, 那种愉悦和满足不言而喻。但是有没有想过如何发布让其他人共享你的成果呢？当然！使用heroku,输入下面的命令就可以轻松的帮你完成。git push heroku master那如果同时要发布6 ，7个项目呢？项目之间可能共用数据库，共享若干代码。情况似乎就...", "content": "作为一个程序员， 每天开心的新程序，让所有的测试通，最后打浏览器，输入“localhost/newapp”， 看到开发的功能展现在眼前, 那种愉悦和满足不言而喻。但是有没有想过如何发布让其他人共享你的成果呢？当然！使用heroku,输入下面的命令就可以轻松的帮你完成。git push heroku master那如果同时要发布6 ，7个项目呢？项目之间可能共用数据库，共享若干代码。情况似乎就不那么简单。需要考虑的因素很多，其中集成无疑是非常重要的，下面两点，可见一斑。1、 与其他项目的集成一个很简单的例子。我们的项目的唯一入口是另一个项目中一个连接old link: http://host/show?name=jiangpengnew link: http://host/show需求是把old link改成new link,以前name参数是必传的,否则就会失败，现在是可选择的。我们对自己的代码库非常熟悉，很快将验证必选的逻辑去掉。接下来就要去修改另一个代码库，那是个陈旧的用Perl完成的代码，修改完成之后甚至不知道怎么运行测试，而且CI还是红的,没法build出package,也没法提交。过了两天才顺利的做完，build出最新的版本，deploy到cloud上，功能完美，QA竖起大拇指说做的不错，没有bug！等到发布的时候只要把最新的包部署到production上面。这样就可以了么？不行！当前对于两个工程的修改在发布时是有依赖的。如果Perl工程先发布，就必然导致在我们工程发布之前的这个时间段，我们的功能将无法访问。通常，发布会持续两三天，也就是说最坏的情况，三天之内我们的应用都不可用。 这对于要求7*24小时在线的应用来说是不可接受的。其实这个问题是可以避免，在cloud上我们有E2E的测试，但是由于要在那个环境上做BAT，所以恰好关掉了cloud的自动部署。虽然只是这么微小的改变都有可能导致产品无法访问的巨大后果，这就是集成考虑不全面的后果。2、与数据库的集成发布从大的方面可以分为数据库与代码库两个部分，数据库先于代码库发布，如果发布持续3天，通常第一天第一步就是应用所有的数据库修改，然后陆续的发布不同项目的代码。如果只是增加新列或表，这个过程没有问题。如果是修改列名呢？按照前面的发布顺序，数据库发布之后，代码发布之前，应用必然异常，会提示数据库列不存在。以下的几个方案可以考虑实施： 不要在最开始就执行数据库的修改，可以将修改列名这一个操作放在发布对应代码之前。这种方案其实就是缩短两者之间的时间差，期望在这个时间段内没有用户访问。 与Business的人商量，如果允许产品下线，那么采用步骤1即可。通常Business的人对这种要求都会比较谨慎的思考，所以提出这样的建议前，也需要想清楚可否避免。与发布相关的集成点有的时候需要dev在开发结阶段不要仅仅局限于代码功能完成本身,而需要从发布的角度仔细想想才会避免. 当然更加科学的做法是通过足够的自动化测试来保证，纯粹靠程序员的思考，很难保证每一次都不出问题。《软件开发沉思录–ThoughtWorks文集》中的第一章：Solving the Business Software “Last Mile”，更加详细和理论的阐述了大型项目发布的问题，不论是否参与过这样的发布, 都值得学习一下。" }, { "title": "软件发布实战 -- 状态检查", "url": "/posts/releae-in-action-healthcheck.html/", "categories": "工作", "tags": "Release, Integration, Feedback, Health Check", "date": "2011-10-16 00:00:00 +0800", "snippet": "当前项目的发布周期是两个星期,指的是总共6,7个项目一起发布。从第一天code cut，经历如下的过程：总共三个阶段，每次发布上去以后各个项目都要进行回归测试，发现bug就需要打tag，重新经过QA环境。如果每次环境保持比较稳定，比如发布的操作系统，部署方式都没有改变，那基于已有稳定cloud环境保证的基础上，不会打太多tag。但是我们就经历了上面两种方式的变化。系统从Debian改为Cen...", "content": "当前项目的发布周期是两个星期,指的是总共6,7个项目一起发布。从第一天code cut，经历如下的过程：总共三个阶段，每次发布上去以后各个项目都要进行回归测试，发现bug就需要打tag，重新经过QA环境。如果每次环境保持比较稳定，比如发布的操作系统，部署方式都没有改变，那基于已有稳定cloud环境保证的基础上，不会打太多tag。但是我们就经历了上面两种方式的变化。系统从Debian改为CentOS，部署方式从同一个appliction变为两个application，同一台VM， 进而变为两个application，两个VM。这一次，在很短的时间里tag的数量就飙升到20。在如此紧密的发布，这么多的小版本中，如何快速完成下面两个检测呢？ 快速查看发布了正确的版本。可以点击查看当前版本中更新的内容，但显然这需要记住每个tag更改的内容，在tag较多团队太多时不实际。&lt;/li&gt; 快速查看基础架构(比如数据库连接)运行良好。运行测试可以做到，但依然效率太低。&lt;/li&gt;Live Version和Health Check可以实现这一点。1、Live Version也就是显示当前运行的版本。Rails中默认显示index页面，我们可以将这个页面稍作改变，以支持版本显示。#live_version.html.erb&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta name=\"package-git-sha\" content=\"&lt;%= package_git_sha %&gt;\"&gt; &lt;title&gt;Version: &lt;%= package_version %&gt;, &lt;%= package_git_sha %&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt;&lt;%= package_version %&gt;&lt;/body&gt;&lt;/html&gt;#version tasktask :version do write_version_file(\"live_version.html.erb\", \"public/live_version.html\") write_version_file(\"live_version.yml.erb\", \"live_version.yml\")end#get version from jenkinsdef package_version_label build_id = ENV['BUILD_NUMBER'] || 'dev' \"1.#{build_id}\"end最上面是显示版本的页面模板, 默认的index链接到这个模板。下面是rake task, 当package整个应用时将给version具体的信息。其中用到了Jenkins Parameter的属性。这样当访问应用的根目录时会显示程序的版本信息， 实现中， 如果是普通提交构建，版本会使用时间戳，如果是Tag版本构建，会显示Git tag+ Build number+ App name的格式。2、Health Check它的作用在于快速显示程序的基本状态，比如数据库链接是否正常。我们使用了heartbeat和status两种: Heartbeat: 当一切正常返回OK。通常在发布过程中发布了一个应用后都会去检查Hearbeat是否正常。如果异常，将使用status来查看细节。 Status：显示每个连接的具体状态，仅在Heartbeat异常时帮助定位。发布的过程并不需要每个分支去测试，因为基本的功能实现有各种单元测试和集成测试，所以这种状态信息的快速反馈十分必要，这是加快发布的重要一环。" }, { "title": "Express Js", "url": "/posts/express-js.html/", "categories": "技术", "tags": "Express, Javascript, NodeJS", "date": "2011-07-04 00:00:00 +0800", "snippet": "Javascript通常运行于客户端浏览器，可以方便的操作HTML中的DOM元素，另外，提供也提供了一些事件响应机制，将表单验证等很多功能置于前台完成，降低前端与服务器端的交互次数，提高用户体验。在服务器端，有很多的框架可以选择，包括SSH，Spring MVC，ASP.Net MVC等，这些框架提供了良好的结构，可以创建强健的Web应用。然而，前端与后端的割裂在某种程度上限制了Web开发人...", "content": "Javascript通常运行于客户端浏览器，可以方便的操作HTML中的DOM元素，另外，提供也提供了一些事件响应机制，将表单验证等很多功能置于前台完成，降低前端与服务器端的交互次数，提高用户体验。在服务器端，有很多的框架可以选择，包括SSH，Spring MVC，ASP.Net MVC等，这些框架提供了良好的结构，可以创建强健的Web应用。然而，前端与后端的割裂在某种程度上限制了Web开发人员的全面发展，而且我们往往需要可以快速的创建我们的应用系统，在这一点上，上面的框架显得过于笨重。如果可以让前后台可以无缝连接，那么将会大为简化系统的开发，基于Node.js的Express就是这样一种框架。谈到Express就必须要了解Node.js，Wikipedia对Nodejs的定义是： Node.js is an event-driven I/O server-side JavaScript (on V8 JavaScript engine) environment for Unix-like platforms. It is intended for writing scalable network programs such as web servers. It was created by Ryan Dahl in 2009, and its growth is sponsored by Joyent, which employs Dahl. Node.js is similar in purpose to Twisted for Python, Perl Object Environment for Perl, libevent for C and EventMachine for Ruby. Unlike most JavaScript, it is not executed in a web browser, but is instead a form of server-side JavaScript. Node.js implements some CommonJS specifications. Node.js includes a REPL environment for interactive testing.当前web的应用的现状：很多应用（如聊天室，网络游戏等）都希望在连接建立以后始终保持这个连接，随时与发送请求获取响应。传统的服务器，为每个请求单独开始新的线程，在客户并发请求数量巨大的情况下，使用传统的方式实现资源的合理配置并不容易。而Node.js使用事件驱动，通过这种方式以单线程的方式实现并发的快速响应，所有的方法都通过回掉方式进行处理，之后回到事件循环。而在实践循环的时间，可以随时接受新的事件，CPU不会有任何的消耗。本文不是要详细介绍Node.js，而是Express框架，希望通过Route，View，Database这三个方面的实现来与传统的web框架作比较，来分享服务器端的实现的简洁与强大。1. Route app.get('/user/:id', function(req, res){ res.send('user ' + req.params.id); })上面代码在当用户访问”http://server:port/user/1”这样的地址时触发，执行上面所定义的匿名函数，参数1会放入req.params.id中。这里还支持使用正则表达式匹配更多的情况。MiddlewareExpress中，可以对某个请求进行顺序的若干处理，比如从数据库加载用户信息，判断用户权限，然后操作数据。这可以使用Middleware完成。Middleware与普通的回掉函数不同的地方在有另一个函数作为参数，通常叫做next()。当在某个Middleware中调用next()时，系统会自动调用下一个匹配的路由进行处理。Route Param Pre-conditionsapp.param('userId', function(req, res, next, id){ User.get(id, function(err, user){ if (err) return next(err); if (!user) return next(new Error('failed to find user')); req.user = user; next(); });});app.get('/user/:userId', function(req, res){ res.send('user ' + req.user.name);});上面的代码中，当请求该路由时，会先执行param，这里通常可以进行一些校验，从数据库读取数据等等任务，之后基于Middleware的功能，调用next()，转回主回掉函数。Struts使用极为复杂的配置来实现路由功能，Spring MVC加入了annotation，在代码可读性上有了较大提高，但依然没有这里的直接。同时Middleware，特别是Route Param Pre-conditions类似于AOP，可以在真正的业务逻辑处理前进行预处理工作，使代码更清晰简洁。2. ViewExpress支持Haml， Jade， EJS， CoffeeKup，jQuery等视图。可通过app.set(‘view engine’, ‘jade’)加载并激活对应的template，Jade是Express中默认的template。下面代码实现了在render页面以及页面与后台的数据绑定(使用hmal作为view engine)%h1= title%form{ method: 'post' }  %div    %div      %span Title :      %input{ type: 'text', name: 'title', id: 'editArticleTitle' }    %div      %span Body :      %textarea{ name: 'body', rows: 20, id: 'editArticleBody' }    %div#editArticleSubmit      %input{ type: 'submit', value: 'Send' }get('/blog/new', function(){ this.render('blog_new.html.haml', { locals: { title: 'New Post' } });});post('/blog/new', function(){ var self = this; articleProvider.save({ title: this.param('title'), body: this.param('body') }, function(error, docs) { self.redirect('/') }); 3. Database由于JSON是天然的javascript数据传递格式，可以看到在路由定义中render view使用的变量定义也是通过JSON的格式进行，所以Express自然对基于document的数据库提供了良好的支持，也就是Mongo DB。它的driver是node-mongodb-native，通过下面的代码就可以使用mongo。var mongo= require('mongodb').Dbdb= new Db('db-name', new Server(host, port, {auto_reconnect: true}, {}));db.open(function(){});" }, { "title": "Box2D-Post Collision Detection", "url": "/posts/box2d-post-collision-detection.html/", "categories": "技术", "tags": "Box2D, Collision Detection, Physics Engine", "date": "2011-06-01 00:00:00 +0800", "snippet": "Demo在检测到碰撞后，我们往往需要进行一些处理，比如在Angry Birds中当小鸟撞击到障碍或者击中猪后，会有碰撞的声音，破碎的效果等，这些都是在碰撞检测后进行处理的。如上图，坦克发出的炮弹击中了空中飞行的物体，之后炮弹消失，物体旋转下落。实现的代码如下var contactListener = new Box2D.Dynamics.b2ContactListener;contactLi...", "content": "Demo在检测到碰撞后，我们往往需要进行一些处理，比如在Angry Birds中当小鸟撞击到障碍或者击中猪后，会有碰撞的声音，破碎的效果等，这些都是在碰撞检测后进行处理的。如上图，坦克发出的炮弹击中了空中飞行的物体，之后炮弹消失，物体旋转下落。实现的代码如下var contactListener = new Box2D.Dynamics.b2ContactListener;contactListener.BeginContact = function(contact) { var bullet = contact.GetFixtureB().GetBody(); var fly = contact.GetFixtureA().GetBody() var fly_data = fly.GetUserData() if(bullet.GetUserData() == \"bullet\" &amp;&amp; fly_data != null &amp;amp;&amp;amp; fly_data.indexOf(\"fly\") != -1){ trace(\"bullet collision detected\"); bullet.SetUserData(\"dead\") fly.SetLinearVelocity(new b2Vec2(0, 3)) fly.SetAngularVelocity(2) } };Box2D中Body拥有一个userData属性，可以在里面存储任何数据。当引擎检测到碰撞时，就会回掉上面的函数，此时可以使用userData中存储的数据来判断碰撞的对象。对于上面的效果，首先根据userData判断出子弹和物理，然后设置炮弹的userData为dead，以及给飞行物体设置新的线速度和角速度。这样飞行物体就会改变飞行状态，而在下一次的界面update操作中可以destroy所有dead的物体。这里需要注意的是不能直接在回掉函数中destroy body，box2D不允许这样做，原因是body可能用于与其他物体的碰撞检测中。所以只能在回掉函数中记录需要destroy的物体并且在更新函数中销毁。" }, { "title": "Box2D-Collision Detection", "url": "/posts/box2d-collision-detection.html/", "categories": "技术", "tags": "Box2D, Physics Engine", "date": "2011-06-01 00:00:00 +0800", "snippet": "Demo碰撞检测是物理引擎中非常重要的部分，一般分为两种： Discrete Collision Detection: 离散碰撞检测。从实现的角度来说，就是在每TimeStep时刻计算所有当前物体的Contact，由于Box2D处理的都是刚体，这样如果在计算的结果中有overlap的刚体存在，那么这些物体之间必然存在碰撞关系。 CCD(Continuos Collision Detect...", "content": "Demo碰撞检测是物理引擎中非常重要的部分，一般分为两种： Discrete Collision Detection: 离散碰撞检测。从实现的角度来说，就是在每TimeStep时刻计算所有当前物体的Contact，由于Box2D处理的都是刚体，这样如果在计算的结果中有overlap的刚体存在，那么这些物体之间必然存在碰撞关系。 CCD(Continuos Collision Detection): 连续碰撞检测。与离散检测不同，并不是只在某些时刻检测碰撞情况，而是根据物理学的相关知识，通过当前的速度，加速度，位置，方向等信息计算在每个离散采样时间间隔内的运动轨迹，以轨迹来判断是否存在碰撞。既然两种方式存在，那么如何选择，他们之间有怎么样的区别呢？Tunneling下面的图可以用来揭示部分原因第一张图中，假设一个物体以恒定速度从左向右运动，物理引擎分别在t1,t2,t3时刻采样，这样在t2时刻物体处于障碍物前方，而t3时刻位于障碍物右方，这就好像物理穿过了障碍物。这种现象叫做Tunneling，也是离散碰撞检测带来的问题。同样的现象如第二张图，坦克发射的炮弹落在了障碍物的中间，这是因为穿过了前面的物体，而恰好没有穿过后一个。CCD由于计算了物理的运动轨迹，它与障碍物之间就会有交叉，所以不会产生Tunneling现象。Box2D中，static与dynamic物体之间的以及kinematic与dynamic物体之间都是使用CCD，所以这两类物体之间不会错过任何碰撞。但是dynamic物体之间默认采用离散检测，而将与CCD的控制转换通过Body的bullet属性交给设计者。当此属性为true的时候，就对该物体使用CCD。除了使用CCD可以消除Tunneling想象外，也可以通过提高采样频率来降低它发生的概率，例如上面的途中，如果将采样频率提高一倍，就恰好可以检测到碰撞。无论使用何种方式当检测到碰撞后，都需要计算物体发生碰撞的时刻，因为刚体不允许出现overlap，所以需要将物体恢复到发生碰撞的时刻，等待下一次界面更新，渲染碰撞效果。这个第一次碰撞的时间叫做TOI(Time of Impact)。两种碰撞检测方式的取舍就是性能与精确度的权衡，一般来说可以从下面的角度来考虑： CCD非常昂贵。相对于只有固定间隔的离散检测来说，时间变量的引入使引擎的计算工作加大，当物体较多时，影响更为明显。 CCD应该只用于高速运动的关键物体。比如Angry Birds中发射的小鸟，玩家绝对不能接受小鸟穿过障碍物。 不是所有高速物体都要使用CCD，因为往往当物体速度非常块时，我们是希望忽略它的碰撞关系的。 不要将CCD应用于在初始位置已经接触的物体。" }, { "title": "Box2D--Physics Engine", "url": "/posts/box2d-physics-engine.html/", "categories": "技术", "tags": "Box2D, Physics Engine", "date": "2011-04-17 00:00:00 +0800", "snippet": "DemoBox2D是一个强大的物理引擎(Physics Engine)，有c++, java, js等多种版本。当前流行的Angry birds游戏就使用它作为物理引擎。Wikipedia中给出的定义是： A physics engine is computer software that provides an approximate simulation of certain simp...", "content": "DemoBox2D是一个强大的物理引擎(Physics Engine)，有c++, java, js等多种版本。当前流行的Angry birds游戏就使用它作为物理引擎。Wikipedia中给出的定义是： A physics engine is computer software that provides an approximate simulation of certain simple physical systems, such as rigid body dynamics(including collision detection), soft body dynamics, and fluid dynamics, of use in the domains of computer graphics, video games and film. Their main uses are in video games (typically as middleware), in which case the simulations are in real-time. The term is sometimes used more generally to describe any software system for simulating physical phenomena, such as high-performance scientific simulation.近期为了给Tankcraft做spike，实现了一个简单的坦克，包括的功能有： 左右键控制坦克前后移动 上下键调整炮筒的角度 空格键发射炮弹，根据炮筒角度不同炮弹运行的抛物线也不一样 当运行到有坡度的地面时，坦克整体布局不发生改变其中关键技术点包括：Body:在Box2D中，整个界面成为一个World，World中可以创建多个不同的Body，Body可以具有质量，摩擦力，位置，形状等等属性。例如上图中坦克的底座，操作舱，轮子，炮筒，炮弹，斜坡，四周方框都是Body。Body共有三种： staticBody：不能有任何移动和变化。例如，四周方框和斜坡 dynamicBody: 可以任意移动变化。除过方框和斜坡外的其余部分都是这种类型 kinematicBody：通常用于给定初始速度后可以移动的物体Body Joint:多个Body之间可能毫无关系，也可能紧密结合，Body Joint就是用来处理不同\bBody之间关系的一个对象。共有9种Joint： Distance Joint Friction Joint Gear Joint Line Joint Mouse Joint Prismatic Joint Pulley Joint Revolute Joint Weld Joint有一篇blog对joint讲解的非常详细：，这里不再详述每种joint的适用场景。只简单列举用到的两种： Weld Joint: 这应该是最简单最直接的一种连接，就是将两个Body绑定在某个点上。例如操作舱和坦克底部，它们彼此绑定而且没有相对移动。 joint = new b2WeldJointDef; var car_body_position = car_body.GetPosition() joint.Initialize(car_body, car_head, new b2Vec2(car_body_position.x - 50/30, car_body_position.y)); world.CreateJoint(joint) Revolute Joint：这种方式是用来处理两个Body之间旋转的一种连接，例如车轮和底座之间，以及炮筒与操作舱之间。 var joint = new b2RevoluteJointDef; var joint_point = new b2Vec2(car_head.GetWorldCenter().x + 25/30, car_head.GetWorldCenter().y) joint.Initialize(gun, car_head, joint_point); joint.enableLimit = true; joint.referenceAngle = 20 * Math.PI / 180 gun_joint = world.CreateJoint(joint) 这里定义了在Joint时两个Body的初始角度差。另外要特别注意的就是，定义的joint_point是car_head的最后端，而gun的Position一定要根据car_head的Position设置正确，保证gun的最左端与joint_point重合，否则无法实现合理的绕joint_point旋转的效果！ ApplyImpulse: 这个用来给发出的炮弹初始速度以及角度。由于炮弹必须要沿着炮筒的方向，所以需要理解这个方法的参数含义，并且考虑几个关键点坐标来计算。 var bulletDef = new b2BodyDef; bulletDef.type = b2Body.b2_dynamicBody; fixDef.shape = new b2CircleShape( 4/30 ); fixDef.friction = 4 fixDef.density = 2 fixDef.filter.groupIndex = 1; var gun_joint_position = gun_joint.GetAnchorA() bulletDef.position = new b2Vec2(2 * gun.GetPosition().x - gun_joint_position.x, 2 * gun.GetPosition().y - gun_joint_position.y); var bullet=world.CreateBody(bulletDef); bullet.CreateFixture(fixDef); bullet.ApplyImpulse(new b2Vec2(gun.GetPosition().x - gun_joint_position.x, gun.GetPosition().y - gun_joint_position.y), gun_joint_position) 以下是一些有用的链接： http://www.box2dflash.org/docs/2.1a/reference http://www.box2d.org/manual.html http://blog.allanbishop.com/box2d1a-tutorial-part-2-joints http://www.box2d.org/index.html" }, { "title": "Validation Refactor -- Command Pattern", "url": "/posts/validation-refactor.html/", "categories": "技术", "tags": "Command Pattern, Refactor, Test", "date": "2011-03-17 00:00:00 +0800", "snippet": "曾经遇到过几次如下的代码public void validate(Person person, List&lt;String&gt; errors) { if (!validateName(person.getName())) { return; } if (!validatateAge(person.getAge())) { return; } if (!valida...", "content": "曾经遇到过几次如下的代码public void validate(Person person, List&lt;String&gt; errors) { if (!validateName(person.getName())) { return; } if (!validatateAge(person.getAge())) { return; } if (!validateHeight(person.getHeight())) { return; } System.out.println(\"Validation Success!\");}这一个Validator中的方法，对Person对象的三个属性进行校验，当某个属性失败时，将错误信息加入errors中，然后停止校验。这是个简单的例子，可以想象，当对象比较复杂，属性很多时，此方法将会相应增加很多if和return，非常难看。由于每个属性的校验都有return语句，所以无法通过抽取方法来重构。今天米高告诉了一种方案，经过验证，效果不错。方案如下：public interface StopableMethod { boolean excute();}public class Excutor { private List&lt;StopableMethod&gt; methods; public Excutor(List&lt;StopableMethod&gt; methods) { this.methods = methods; } public void excute(){ for (StopableMethod method : methods) { if(!method.excute()){ break; } } }}public class ValidateName implements StopableMethod { private String name; public ValidateName(String name) { this.name = name; } public boolean excute() { if (name == null) { System.out.println(\"Name invalid.\"); return false; } return true; }}其中牵扯了三个部分 StopableMethod:所有验证方法实现的接口 Excutor：遍历执行所有方法，方法返回false则终止 ValidateName:校验Name的方法，实现上述接口。每个属性的校验方法都按照这个类实现重构后调用的代码如下@Testpublic void should_fail_fast_when_validation_error() { person.setName(null); person.setAge(0); List&lt;StopableMethod&gt; methodList = new ArrayList&lt;StopableMethod&gt;(); methodList.add(new ValidateName(person.getName())); methodList.add(new ValidateAge(person.getAge())); new Excutor(methodList).excute();}调用时，将所有验证方法的List传递给Excutor，执行excute即可。这样重构虽然增加了很多validate类，但是每个都很小，测试很简单，而且在测试中互相没有任何影响。实际上，这是Command Pattern的一种实现，典型的Command Pattern结构如下其中的对应关系为 Command：StopableMethod Concrete: ValidateName Receiver: Person Invoker: Excuter Client: Test方法Command Pattern通常应用于以队列或堆栈的形式保存一组命令对象的场景，如：Multi-level undo，Transactional behavior， Progress bars， Wizards， GUI buttons and menu items， Thread pools， Macro recording， Networking， Parallel Processing， Mobile Code。From: http://en.wikipedia.org/wiki/Command_pattern" }, { "title": "路漫漫", "url": "/posts/on-the-way.html/", "categories": "工作", "tags": "压力, 沟通, Showcase", "date": "2011-01-23 00:00:00 +0800", "snippet": "还有一个星期就将结束此次悉尼之行，不用再穿着衬衫皮鞋，有机会舒服的坐在自己宽敞的Office里，吃点水果，听听session，想起来感觉真好。从去年11月开始到现在，前后辗转两个公司，八周时间。不得不说，逝去的，是出国的兴奋，经历的，是时间的漫长和痛苦。周末出去玩一玩，吃点各国美食，已无法抵消工作中各种各样的打击、失落、压力、迷茫。存在感这个词可以用来衡量自己在团队中所处的位置，存在感越强，...", "content": "还有一个星期就将结束此次悉尼之行，不用再穿着衬衫皮鞋，有机会舒服的坐在自己宽敞的Office里，吃点水果，听听session，想起来感觉真好。从去年11月开始到现在，前后辗转两个公司，八周时间。不得不说，逝去的，是出国的兴奋，经历的，是时间的漫长和痛苦。周末出去玩一玩，吃点各国美食，已无法抵消工作中各种各样的打击、失落、压力、迷茫。存在感这个词可以用来衡量自己在团队中所处的位置，存在感越强，对团队越重要。工作中的具体表现是：可以在讨论中贡献自己的观点，可以在开发中承担重要的职责，可以在他人遇到困难时给与帮助。从这几个角度讲，我的存在感趋近于零。如果加上完成若干个Story的话，那还可以勉强说有一些，但是这是最若的环节，因为这是最可以被替代的。在客户现场工作，需要8个小时精神高度集中。特别是第二个项目，只有我和米高两个人，但是这是一个团队，一个人的低效就意味着团队损失了一半的战斗力，甚至更多，因为另一方需要花费更多的精力来弥补这一方的缺失。曾经两三次，莫名我的效率出奇的低，那几天也就是打击和失落感最强的几天。两个人的团队，没有任何缺点可以隐藏，没有多少希望另一方在现场工作中随时给与帮助，只有自己在下班后和同伴交流，思考，制定后面的计划，改进，然后实践。语言无论如何，这都是一个硬性的东西。似懂非懂基本是每次会议的主要感觉，当然，这就更加无法发表什么意见，所有的精力都用在听的上面，很难在这个基础上再增加思考的功能。相处第一个项目是和自己的团队以及客户一起工作，每天和自己的人pair（Jak，很nice的一个人，每天不停的说话），那种感觉很好的，看着完成的Story在客户给用户Showcase的时候得到很高的赞扬，心里还是有不少的满足感。但是，这完全不够！第二个项目，大部分时间，完成Story以及熟悉现有的系统，一个人。用米高的话说，这是躲在角落里编程。和客户交朋友，是除了项目本身的内容之外可以对项目完成起到重要帮助的环节，而对我，这个到最后我也做得不好。当然，不想把这篇博客变成倾诉痛苦的地方，毕竟待的时间也不短了，也需要总结一下为数不多几点经验和体会：准备当能力不足以完全胜任客户现场的工作时，充分的准备是唯一可控的方面。过去两周的两次Showcase和一次需求澄清会议我的印象很深刻。共同点是 我是百分百的参与者 我很自信地和客户交流 我完全听懂他们说什么 我得到米高的称赞（也许前面太差了这里正常一些都觉得难能可贵了。。）而之所以这样是因为我做了非常充分的准备。Showcase要得益于是Koch的时候有过小罗的培训以及实践，略有不同的是这次客户就坐在旁边。这会议，是因为我近一段时间都在分析那个模块的业务，有很多的理解和疑问。当准备足够充分，就有足够的信心表达。国外客户会议的相同点是每个人的思维都很快，一个人发言刚结束另一个人会立刻开始，没有任何的停顿。如果这个时候不是完全听明白，或者正在尝试记录一些内容，那基本上很难有机会发表意见，除非那个问题就是针对你，大家刻意停下来等待你的回应。交流第二次过来，在几次的Friday Lunch中遇到前次项目中合作过的同事，感觉格外的亲切，几乎每个人都单独聊过。这种感觉很奇妙，因为这些人在上次来的时候其实也没有说过多少话。我想如果再见到前面的客户，也会有相似的感觉。更加主动的交流。这是语言想要进步所必需而且最有效的吧，除了与同事的沟通，在皇家植物园与遛狗的爷爷，在菜市场与卖菜的大妈，在吃饭时与同座的年轻人…当主动去说，就会越想说，反之只会退缩。逝去的，经历的，都是过去式，这段时间留下的至深感触也许很久都不会忘记，这个值得记录并珍惜。到现在正式工作已经18个月了，如果换作一份普通的程序员工作，编写并维护某个代码模块，一年半的时间足以完全掌控那个模块，足以轻松自如地应付每天的工作。\u001c但是现在，也许是咨询师这个特殊的身份，决定了不是轻松的应付代码就是全部。我感觉到的，是一个长远而艰难的漫漫长路，似乎一切都还只是起步，而后面无数的未知。什么时候可以回头看见自己已经在这条路上走了精彩的一段了呢？期待中……" }, { "title": "Hello Mule ESB", "url": "/posts/hello-mule-esb.html/", "categories": "技术", "tags": "mule ESB", "date": "2011-01-13 00:00:00 +0800", "snippet": "这些天在一个庞大的J2EE遗留系统中工作，其实很想体验真正企业级应用是如何实现的。不过每天忙于应付ERB、Service、Dao、Validator .xml 等文件，修复Bug，感受到的只是众多的Class和Config，以及由此导致的启动JBoss花费4分钟多（只publish三个EAR）和尝试用IntelliJ打开要等很久很久很久，最终放弃的痛苦。今天这样的心情有所不同，接触了一个之前...", "content": "这些天在一个庞大的J2EE遗留系统中工作，其实很想体验真正企业级应用是如何实现的。不过每天忙于应付ERB、Service、Dao、Validator .xml 等文件，修复Bug，感受到的只是众多的Class和Config，以及由此导致的启动JBoss花费4分钟多（只publish三个EAR）和尝试用IntelliJ打开要等很久很久很久，最终放弃的痛苦。今天这样的心情有所不同，接触了一个之前似乎在哪里看到过名字的东西叫做Mule ESB。是否使用Mule ESB可以从下面的mulesoft网站给出的五个问题来考虑: Are you integrating 3 or more applications/services? Will you need to plug in more applications in the future? Do you need to use more than one type of communication protocol? Do you need message routing capabilities such as forking and aggregating message flows, or content-based routing? Do you need to publish services for consumption by other applications? 也可以这样理解，Mule ESB就是用来解决上述问题才需要引入，而这种复杂性以及扩展性恐怕也只有在企业级的应用中才会出现，之前只是了解SSH，这些还远远不够。进入正题。其实今天也就是跑通了Hello world以及在示例代码中增加了一个很小的功能。。。这个Hello world的功能是：用户输入名称name，有两个Service来处理，第一个处理成Hello + name, 第二个进一步处理成Hello + name，how are you？这是个简单的模型，特别之处在于这两个Service彼此之间没有任何直接的通信，消息（name）的流转处理通过一个hello-config配置，每个Service只完成自己对输入消息的处理，然后输出即可。mulesoft网站上有张图对这个功能作解释非常合适，转载一下其核心的配置如下：&lt;model name=\"helloSample\"&gt; &lt;service name=\"GreeterUMO\"&gt; &lt;inbound&gt; &lt;stdio:inbound-endpoint system=\"IN\" transformer-refs=\"StdinToNameString\"/&gt; &lt;/inbound&gt; &lt;component class=\"org.mule.example.hello.Greeter\"/&gt; &lt;outbound&gt; &lt;filtering-router&gt; &lt;vm:outbound-endpoint path=\"chitchatter\"/&gt; &lt;payload-type-filter expectedType=\"org.mule.example.hello.NameString\"/&gt; &lt;/filtering-router&gt; &lt;/service&gt; &lt;service name=\"ChitChatUMO\"&gt; &lt;inbound&gt; &lt;vm:inbound-endpoint path=\"chitchatter\" transformer-refs=\"NameStringToChatString\"/&gt; &lt;/inbound&gt; &lt;component class=\"org.mule.example.hello.ChitChatter\"/&gt; &lt;outbound&gt; &lt;pass-through-router&gt; &lt;stdio:outbound-endpoint system=\"OUT\" transformer-refs=\"ChatStringToString\" /&gt; &lt;/pass-through-router&gt; &lt;/outbound&gt; &lt;/service&gt; &lt;/service&gt; &lt;/model&gt;这里面声明了两个Service分别对应前面功能说明中Service，比较重要的配置是： transformer-refs：在进入处理的Component之前会执行这里指定的方法，主要用来进行类型转换 vm:inbound-endpoint/vm:outbound-endpoint: 指定一个输入输出的path。在这里GreeterUMO以chitchatter作为输出路径，ChatUMO以它作为输入，这样就会在这个path上监听，得到前者发出的消息。 component：数据处理，这里指定了类，但没有指定具体方法，mule会在运行是根据参数类型来确定执行的方法。Greeter类中就会执行参数类型为NameString的方法。 public Object greet(NameString person){ person.setGreeting(greeting); } 当然如果有两个方法类型相同，就会抛出异常，需要额外的配置（不过现在我还不清楚，留待后续研究。。） 这个Hello world还是比较简单的，两个Service都是在同一个工程下，使用相同的配置文件。如果是在不同的工程里，该怎么做呢？还有很多要研究！" }, { "title": "Web Framework大杂烩之Data Binding", "url": "/posts/web-framework-data-binding.html/", "categories": "技术", "tags": "Rails, Spring MVC", "date": "2011-01-11 00:00:00 +0800", "snippet": "昨天在使用Spring MVC做界面，一边做一边在想着前面使用ASP.NET MVC时是如何实现的。在花了一段时间把CRUD搞定之后，不禁感叹，做到这个程度，似乎也就是做了Rails中下面的一句话：rails generate scaffold于是，我觉得似乎有必要把接触过的这几个框架做个比较，至少从应用层面可以对Rails, Java和 .NET有个结构性的认识。既然是从做View时想到的...", "content": "昨天在使用Spring MVC做界面，一边做一边在想着前面使用ASP.NET MVC时是如何实现的。在花了一段时间把CRUD搞定之后，不禁感叹，做到这个程度，似乎也就是做了Rails中下面的一句话：rails generate scaffold于是，我觉得似乎有必要把接触过的这几个框架做个比较，至少从应用层面可以对Rails, Java和 .NET有个结构性的认识。既然是从做View时想到的这些，那么就先比较一下View中的Data Binding，也有的称为Model Binding。当我们提交表单时，如果完全手工处理，那么需要在后台从Request中取出每个Field的值，然后组装为需要的Model对象。当表单比较大，Field比较多时，就演变成了纯粹的体力劳动。这种自动包装表单为Model对象的功能就是Data Binding。RailsRails中Convention over Configuration的原则使得不需要任何额外的工作就可以实现banding。# view代码&lt;% form_for(@product) do |f| %&gt; &lt;p&gt; &lt;%= f.label :title %&gt;&lt;br /&gt; &lt;%= f.text_field :title %&gt; &lt;/p&gt; &lt;p&gt; &lt;%= f.label :description %&gt;&lt;br /&gt; &lt;%= f.text_area :description %&gt; &lt;/p&gt; &lt;p&gt; &lt;%= f.submit 'Create' %&gt; &lt;/p&gt;&lt;% end %&gt;#controller代码 def create @product = Product.new(params[:product]) respond_to do |format| if @product.save format.html { redirect_to(@product, :notice =&gt; 'Product was successfully created.') } else format.html { render :action =&gt; \"new\" } end end end其中form_for(@product)是Rails提供的view helper，将界面中的title和description属性与product对象绑定起来，而这个对象在controller中定义。当使用post到create方法时，rails从request params中创建包含数据用于存储的对象.Spring MVC//view代码&lt;form:form action='/product/create.htm' commandName=\"product\"&gt; &lt;form:input path=\"title\"/&gt; &lt;form:input path=\"description\"/&gt; &lt;input type=\"submit\"/&gt;&lt;/div&gt;&lt;/form:form&gt;//controller代码@RequestMapping(value = \"/product/create.htm\", method = RequestMethod.POST)public String create(Product product) { service.save(product); return REDIRECT_LIST_VIEW;}这里view使用&lt;form:form&gt;做view helper，其中的commandName属性指定了使用的model名称，&lt;form:input&gt;用来标明属性来实现binding。实际上，还可以使用另一种数据binding叫做“ModelAttribute”//view代码&lt;form:select path=\"role\"&gt; &lt;form:option value=\"NONE\" label=\"--- Select ---\"/&gt; &lt;form:options items=\"${roles}\"/&gt;&lt;/form:select&gt;//controller代码@ModelAttribute(\"roles\")public ROLE[] roles() { return ROLE.values();}这种做法相当于在controller中声明了一个变量，在view中可以直接以${name}的方式使用。ASP.NET MVC//view代码&lt;% using (Html.BeginForm(\"Create\", \"Product\", FormMethod.Post)) { %&gt; &lt;%= Html.TextBox(\"title\") %&gt; &lt;%= Html.TextBox(\"description\") %&gt; &lt;input type=\"submit\"/&gt;&lt;% } %&gt;//controller代码[AcceptVerbs(HttpVerbs.Post)]public ActionResult Create(Product product){ service.save(product); return RedirectToAction(\"list\");}这里在View中的Binding是通过DefaultModelBinder来实现的。它先查找是否有设定prefix，如果有的话就查找prefix.property，如果没有的话，就直接查找property。这里直接查找property。这也是因为在controller中的Create方法设定了Product参数，如果参数为空，则不会做任何binding。另一种banding是使用ViewData对象，这是ASP.NET MVC Controller提供的内置对象，类似于数组，可以在controller中赋值，在view中取用。另外，如果view继承自ViewPage&lt;%@ Page Title=\"\" Language=\"C#\" MasterPageFile=\"/product.aspx\" Inherits=\"System.Web.Mvc.ViewPage&lt;Product&gt;\" %&gt;则可以直接使用Model来获取数据，Model是ViewData的内置对象。可以看出，三种框架在Data Binding中，共同点就是都注重Name Convention，这也当前发展的趋势吧。" }, { "title": "Dojo submit and Database Engine", "url": "/posts/dojo-submit-and-database-engine.html/", "categories": "技术", "tags": "dojo, InnoDB, MyISAM, mysql", "date": "2010-12-28 00:00:00 +0800", "snippet": "今天给前面纯javascript写的Magic Grid增加一个排行的功能，也就是在玩家完成游戏后，可以输入姓名并提交，可以查看当前排名Top10的玩家名称和分数。功能上并不复杂，不过当前工作的项目是J2EE的，那么就使用相关的技术来实现这个小功能：SSH+MySql+Maven。整个过程中遇到了两个问题印象比较深刻。使用Ajax提交结果Struts常用的Ajax插件有下面几种： ...", "content": "今天给前面纯javascript写的Magic Grid增加一个排行的功能，也就是在玩家完成游戏后，可以输入姓名并提交，可以查看当前排名Top10的玩家名称和分数。功能上并不复杂，不过当前工作的项目是J2EE的，那么就使用相关的技术来实现这个小功能：SSH+MySql+Maven。整个过程中遇到了两个问题印象比较深刻。使用Ajax提交结果Struts常用的Ajax插件有下面几种： Ajax Parts The AjaxParts Taglib (APT) is a component of the Java Web Parts (JWP) project http://javawebparts.sourceforge.net that allows for 100% declarative (read: no Javascript coding required!) AJAX functionality within a Java-based webapp. Dojo The Ajax Tags Dojo Plugin was represented as a theme for Struts 2.0. For Struts 2.1, the Dojo tags are bundled as a plugin. YUI The Yahoo User Interface (YUI) Pluginhas only a few tags are available so far, but the YUI tags tend to be easier to use than the Dojo versions. 对我这个只是提交的小应用来说，几种都差不多，网上似乎关于Dojo的例子不少，所以选用了struts-dojo-tags。使用起来也非常简单， 在pom.xml中加入依赖 &lt;dependency&gt; &lt;groupId&gt;org.apache.struts&lt;/groupId&gt; &lt;artifactId&gt;struts2-dojo-plugin&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt; 在jsp文件头部添加下面一行语句 &lt;%@ taglib prefix=\"sx\" uri=\"/struts-dojo-tags\" %&gt;下面是我第一次写的用来提交的表单代码&lt;s:form action=\"submit\" method=\"post\" theme=\"simple\"&gt; &lt;sx:div id=\"rank\"&gt; &lt;s:label value=\"Input your name: \" for=\"rankBean.name\"/&gt; &lt;s:textfield key=\"rankBean.name\"/&gt; &lt;s:hidden key=\"rankBean.score\"/&gt; &lt;img id=\"loadingImage\" src=\"images/loading.gif\" style=\"display:none\"/&gt; &lt;sx:submit targets=\"rank\" showLoadingText=\"false\" indicator=\"loadingImage\"/&gt; &lt;/sx:div&gt;&lt;/s:form&gt;sx:submit设定了用来接收响应的元素是id为rank的div，在得到响应之前显示一个loading image。这个“照搬”Struts网站上关于Dojo submit使用的代码看似没有问题，但是很tricky的是每次点击submit按钮都会同时发送两个相同的post请求。纠缠了很久才发现，我使用的并不正确，其中id为rank的div不能使用sx:div, 而只要改为struts本身提供的s:div便只会发送一个请求了。但是现在仍然还不知道这样解决的原因何在，网上只找到了一篇相关的blog，只有一个评论──“won’t fix”。有待后续找到答案，也诚恳希望有相关经验的同志们给予答复。###Database Engine在Spring框架内写Hibernate的测试，利用Spring的Transaction机制，可以方便的保持测试数据的整洁。测试代码如下&lt;pre class=\"brush:java\"&gt;@TransactionConfiguration(transactionManager = \"transactionManager\", defaultRollback = true)@Transactional@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = {\"../config/applicationContextForTest.xml\"})public class HibernateRankDaoTest { @Autowired private SessionFactory sessionFactory; @Autowired private HibernateRankDao rankDao; private Rank rank; @Before public void setUp() throws Exception { rank = RankUtil.defaultRank(); rankDao.saveOrUpdate(rank); } @Test public void should_update_rank(){ Rank saved = rankDao.get(rank.getName()); saved.setScore(200); rankDao.saveOrUpdate(saved); Rank result = rankDao.get(rank.getName()); assertEquals(saved.getId(), result.getId()); assertEquals(200, result.getScore()); }}测试功能也非常简单直接，但是无论如何也无法在执行完测试后rollback所有的数据。尝试了各种Spring和Hibernate的配置，都没有作用。最后发现，问题其实是Mysql数据库本身。Mysql默认使用的engine是MyISAM,而它是不支持Transaction的！改成InnoDB，就一切OK了。关于InnoDB与MyISAM比较，可参考[http://www.mikebernat.com/blog/MySQL_-InnoDB_vs_MyISAM](http://www.mikebernat.com/blog/MySQL-_InnoDB_vs_MyISAM)" }, { "title": "HTML5大赛感 (二) : Power of Feedback", "url": "/posts/html5-competition-power-of-feedback.html/", "categories": "工作", "tags": "Feedback, HTML5, Showcase", "date": "2010-12-12 00:00:00 +0800", "snippet": "DemoFeedback是一种文化，也是一种力量。文化：接受Feedback，需要直面批评的勇气，即使这种批评是针对具体的事实。但是我们往往缺乏这样的勇气，甚至对提出的人在心里有某种想法。开始转变心态总是很难，但是接受了这种文化，就可以享受其中。毕竟，如果大家都是提出基于事实的真实感受，那么无论正面或负面都是可以从另一个角度看到自己，因为真实，所以可以不断从中汲取经验和教训，从而提高。力量：...", "content": "DemoFeedback是一种文化，也是一种力量。文化：接受Feedback，需要直面批评的勇气，即使这种批评是针对具体的事实。但是我们往往缺乏这样的勇气，甚至对提出的人在心里有某种想法。开始转变心态总是很难，但是接受了这种文化，就可以享受其中。毕竟，如果大家都是提出基于事实的真实感受，那么无论正面或负面都是可以从另一个角度看到自己，因为真实，所以可以不断从中汲取经验和教训，从而提高。力量：在产品开发中，定期向客户showcase，一方面向客户展示开发进展的情况，使他们有信心和参与度，另一方面是收集客户的Feedback，在小步前进中，随时调整方向，降低风险。这是从这次大赛中感触很深的。在开发的时候，每完成一个小功能，我都会让MG来试玩，获取他最快速的反馈，然后计划下一步首先做哪个功能。两天的时间，大概有五六次这样的showcase。还好传说中曾经扮演过很邪恶的“客户”的MG对我的小应用还是比较容忍，提出非常中肯的建议。回国以后，首先推动西安Office全民参与，得到很多的Feedback，于是增加了图片提示，游戏结束时的正确结果显示，难度调整等。紧接着通过邮件使北京的一些同事也参与进来，于是增加了人员预览，图片放大等功能。最后是Admin Team，于是增加了更多图片，以及后续的扩展计划。随着试玩人数的增加和身份类别的多样，以及针对Feedback改进的不断深入和扩充，小游戏的可玩性\u0010得到了很大的提高，比最初的版本要fancy和健壮了很多。这些Feedback与改进也就发生在短短几天之内，它的强大足以推动这个小游戏从基本山寨发展到还能接受。这次胜出的UFO已经正式应用了一段时间，我想在应用之中一定是得到了很多的Feedback，才足以使它如此成功，受到广大粉丝的热烈欢迎。我们经常应用的TDD、BDD、DDD，上述的模式或许可以称为Feedback Driven Development吧。" }, { "title": "HTML5大赛感 (一)：尝试", "url": "/posts/html5-competition-try.html/", "categories": "工作", "tags": "HTML5", "date": "2010-12-09 00:00:00 +0800", "snippet": "Demo对待事情的第一感觉有时会和事情本身不匹配 (Michael语录) 。比如一件看似不可能的任务，客观条件限制太多。应该如何面对呢？有些人分析所有的不利因素，在心里得出结论，“我不行，那不可能”。最终如大家料想，确实不可能。也有人在大家犹豫的时候已经放手尝试，结果机缘巧合，后续的一切似乎都在谨慎的配合，结果出奇的顺利，回头去想都让自己惊讶。这次的HTML5大赛，我几乎就成了前一种人。比赛...", "content": "Demo对待事情的第一感觉有时会和事情本身不匹配 (Michael语录) 。比如一件看似不可能的任务，客观条件限制太多。应该如何面对呢？有些人分析所有的不利因素，在心里得出结论，“我不行，那不可能”。最终如大家料想，确实不可能。也有人在大家犹豫的时候已经放手尝试，结果机缘巧合，后续的一切似乎都在谨慎的配合，结果出奇的顺利，回头去想都让自己惊讶。这次的HTML5大赛，我几乎就成了前一种人。比赛在11月30日截止，28日刚从前一个项目roll off 的晚上，我无意间看到有些人已经完成了代码开始公测，跟Michael谈论他们做的多好时，他却用那种惯有的煽动语气说:“你也做一个吧!”。我当时心里活动如下: 开玩笑吧，这都啥时候了。 后面两天的行程还不定，可能随时回国或者去客户现场，时间更少了。 大家做得功能看起来都很强大，我两天能做成什么样? HTML5? 不会。CSS3? 略知。如果不是因为在他强大的气场之中，我可能直接就把上述想法原封不动的搬出来了。接下来的几个小时，在他的帮助下， Magic Grid的雏形产生。后面的两天在office on beach，到30日下午完成，然后晚上飞机。这个功能上并不复杂界面也比较简单的小游戏却得到了不少人的支持，我觉得相当一部分原因可能是部分其他的作品功能太复杂，反而不能让\u001c很大家很快上手吧。现在想起来，如果当时后面两天不在office，如果有其它类似但是更加fancy的小游戏，如果不是在一个月前接受了CSS两周特训，如果不是刚刚结束的项目上用了不少JQuery，那么现在我就不会出现在这次比赛的名单之中。一切很巧合，一切又好像很顺利。下一次，当直觉说，这肯定不行时，去尝试一下。" }, { "title": "做一个合格的兼职QA", "url": "/posts/to-be-a-qualified-qa.html/", "categories": "工作", "tags": "DEV, QA", "date": "2010-12-08 00:00:00 +0800", "snippet": "因进度需要，暂时支援一下QA。虽然每天的工作都会和QA接触，不过真正开始成为一个QA的时候，才发现要做的工作很多。QA与DEV显著的一点不同是更关注整体的功能，关注产品的配置与发布，将不同的story之间联系起来，从客户使用的角度来保证产品质量。暂且不说showcase，分析story（兼职BA），与客户沟通需求等，单就测试story就有很多需要注意和学习的地方。设计用例。与分析story的...", "content": "因进度需要，暂时支援一下QA。虽然每天的工作都会和QA接触，不过真正开始成为一个QA的时候，才发现要做的工作很多。QA与DEV显著的一点不同是更关注整体的功能，关注产品的配置与发布，将不同的story之间联系起来，从客户使用的角度来保证产品质量。暂且不说showcase，分析story（兼职BA），与客户沟通需求等，单就测试story就有很多需要注意和学习的地方。设计用例。与分析story的happy path, sad path和bad path类似，要设计各种场景的测试用例。例如，当在没有权限时隐藏了一个连接，那么如果直接使用URL访问，应当以同样抛出没有权限的exception。分析结果。当发现运行结果与期望不同时，可以有以下的步骤：清理上次运行的场景，以干 净的环境重现前次的问题查看log看是否有可用信息，例如环境配置出错等查看代码，分析出错场景对应的代码实现逻辑针对该场景写单元测试或者功能测试这些内容我曾经理解的QA测试时的内容要丰富很多，这是因为如果换作DEV，当QA告诉我story的功能有问题时，我不仅仅是希望 QA向我展示出错的场景，如果可以告诉我是因为某个方法的某个逻辑导致了出现了错误，那么沟通和修改的效率会高很多。我觉得以DEV身份来作为QA，就应当更加深入的分析问题，为DEV提供更多的信息，另外，也可以从实现的角度考虑可能的异常情况，做一个合格的兼职QA。" }, { "title": "Test For DateTime", "url": "/posts/test-for-datetime.html/", "categories": "技术", "tags": "DateTime, Test", "date": "2010-12-08 00:00:00 +0800", "snippet": "在代码中经常遇到在某个方法内部获取当前时间，并对时间进行一定处理。这往往会使测试遇到困难，因为在测试中无法准确获取产品代码内部的当前时间。例如下面的产品与测试代码，public class Product{ public static Product CreateProduct(string name){ Product product = new Product(); ...", "content": "在代码中经常遇到在某个方法内部获取当前时间，并对时间进行一定处理。这往往会使测试遇到困难，因为在测试中无法准确获取产品代码内部的当前时间。例如下面的产品与测试代码，public class Product{ public static Product CreateProduct(string name){ Product product = new Product(); product.name = name; product.timestamp = DateTime.Now; return product; }}[Test]public should_generate_a_product_with_given_name(){ Product product = Product.CreateProduct(\"book\"); Assert.AreEqual(\"book\", product.Name)}这个简单的方法，我们只可以验证name属性，而无法对timestamp做测试，如果在测试中也使用DateTime.Now，则很有可能导致这个测试random success，因为产品代码和测试代码所使用的Now已经不是同一时间，在毫秒级别h会有差异。解决方案有两个： 不准确的验证timestamp的值，而只需要保证这个时间在允许的误差范围内，例如 Assert.IsTrue(DateTime.Now - product.timestamp &amp;lt; new TimeSpan(0, 0, 1) ); 将timestamp的值放在方法签名上作为参数传入。这时方法实现与测试代码将变为 public class Product{ public static Product CreateProduct(string name, DateTime timestamp){ Product product = new Product(); product.name = name; product.timestamp = timestamp; return product; } } [Test] public should_generate_a_product_with_given_name(){ DateTime timestamp = DateTime.Now; Product product = Product.CreateProduct(\"book\", timestamp); Assert.AreEqual(\"book\", product.Name); Assert.AreEqual(timestamp, product.Timestamp); } 在大部分的应用中，对时间没有非常严格的精度要求，所以从代码可测的角度讲，第二种显然更好一些，如果在被测方法内部对时间有更为复杂的处理，那么这种方案的优势会更明显。它让我们对时间可以进行任意设定，有非常灵活的控制。 " } ]
